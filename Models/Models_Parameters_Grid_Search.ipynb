{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f72e9008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from itertools import product, combinations\n",
    "from collections import defaultdict\n",
    "from scipy.stats import chi2_contingency, ttest_ind\n",
    "from gensim.models import Word2Vec\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "current_dir = os.getcwd()\n",
    "project_root = os.path.dirname(current_dir)\n",
    "path = os.path.join(project_root, \"Dataset\")\n",
    "path_results = os.path.join(project_root, \"Results\")\n",
    "excel_file = 'full_validated_dataset.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5e71c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_apriori_pairs_optimized(basket_encoded_values, basket_encoded_columns, min_support, min_confidence):\n",
    "    \"\"\"\n",
    "    Optimized Apriori extraction using pre-computed encodings\n",
    "    \"\"\"\n",
    "    try:\n",
    "        basket_encoded = pd.DataFrame(basket_encoded_values, columns=basket_encoded_columns)\n",
    "        \n",
    "        frequent_itemsets = apriori(basket_encoded, min_support=min_support, use_colnames=True)\n",
    "        \n",
    "        if len(frequent_itemsets) == 0:\n",
    "            return {}\n",
    "        \n",
    "        rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "        \n",
    "        pairs = {}\n",
    "        for _, rule in rules.iterrows():\n",
    "            antecedent = list(rule['antecedents'])[0] if len(rule['antecedents']) == 1 else None\n",
    "            consequent = list(rule['consequents'])[0] if len(rule['consequents']) == 1 else None\n",
    "            \n",
    "            if antecedent and consequent:\n",
    "                pair = tuple(sorted([antecedent, consequent]))\n",
    "                confidence = rule['confidence']\n",
    "                \n",
    "                if pair not in pairs or pairs[pair] < confidence:\n",
    "                    pairs[pair] = confidence\n",
    "        \n",
    "        return pairs\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {}\n",
    "\n",
    "def extract_word2vec_pairs_optimized(transactions, vector_size, window, min_count, similarity_threshold):\n",
    "    \"\"\"\n",
    "    Optimized Word2Vec extraction\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = Word2Vec(\n",
    "            sentences=transactions,\n",
    "            vector_size=vector_size,\n",
    "            window=window,\n",
    "            min_count=min_count,\n",
    "            epochs=10,\n",
    "            sg=1,\n",
    "            seed=42\n",
    "        )\n",
    "        \n",
    "        pairs = {}\n",
    "        vocab_words = list(model.wv.key_to_index.keys())\n",
    "        \n",
    "        for i, word1 in enumerate(vocab_words):\n",
    "            for word2 in vocab_words[i+1:]:\n",
    "                try:\n",
    "                    similarity = model.wv.similarity(word1, word2)\n",
    "                    if similarity >= similarity_threshold:\n",
    "                        pair = tuple(sorted([word1, word2]))\n",
    "                        pairs[pair] = similarity\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        \n",
    "        return pairs\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {}\n",
    "\n",
    "def calculate_agreement_metrics_optimized(apriori_pairs, word2vec_pairs):\n",
    "    \"\"\"\n",
    "    Optimized agreement metrics calculation\n",
    "    \"\"\"\n",
    "    apriori_set = set(apriori_pairs.keys())\n",
    "    word2vec_set = set(word2vec_pairs.keys())\n",
    "    \n",
    "    intersection = apriori_set & word2vec_set\n",
    "    union = apriori_set | word2vec_set\n",
    "    \n",
    "    agreement_rate = len(intersection) / len(union) if len(union) > 0 else 0\n",
    "    \n",
    "    apriori_only = apriori_set - word2vec_set\n",
    "    word2vec_only = word2vec_set - apriori_set\n",
    "    \n",
    "    agreed_apriori_scores = [apriori_pairs[pair] for pair in intersection if pair in apriori_pairs]\n",
    "    agreed_word2vec_scores = [word2vec_pairs[pair] for pair in intersection if pair in word2vec_pairs]\n",
    "    \n",
    "    metrics = {\n",
    "        'agreement_rate': agreement_rate,\n",
    "        'total_pairs': len(union),\n",
    "        'apriori_pairs': len(apriori_set),\n",
    "        'word2vec_pairs': len(word2vec_set),\n",
    "        'agreed_pairs': len(intersection),\n",
    "        'apriori_only_pairs': len(apriori_only),\n",
    "        'word2vec_only_pairs': len(word2vec_only),\n",
    "        'avg_agreed_apriori_score': np.mean(agreed_apriori_scores) if agreed_apriori_scores else 0,\n",
    "        'avg_agreed_word2vec_score': np.mean(agreed_word2vec_scores) if agreed_word2vec_scores else 0,\n",
    "        'intersection_pairs': list(intersection),\n",
    "        'apriori_only_list': list(apriori_only),\n",
    "        'word2vec_only_list': list(word2vec_only)\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def process_single_combination(combo, basket_encoded_values, basket_encoded_columns, transactions):\n",
    "    \"\"\"\n",
    "    Process a single parameter combination\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        apriori_pairs = extract_apriori_pairs_optimized(\n",
    "            basket_encoded_values,\n",
    "            basket_encoded_columns,\n",
    "            combo['apriori_params']['min_support'],\n",
    "            combo['apriori_params']['min_confidence']\n",
    "        )\n",
    "        \n",
    "        word2vec_pairs = extract_word2vec_pairs_optimized(\n",
    "            transactions,\n",
    "            combo['word2vec_params']['vector_size'],\n",
    "            combo['word2vec_params']['window'],\n",
    "            combo['word2vec_params']['min_count'],\n",
    "            combo['word2vec_params']['similarity_threshold']\n",
    "        )\n",
    "        \n",
    "        metrics = calculate_agreement_metrics_optimized(apriori_pairs, word2vec_pairs)\n",
    "        \n",
    "        execution_time = time.time() - start_time\n",
    "        \n",
    "        result = {\n",
    "            'combination_id': combo['combination_id'],\n",
    "            'apriori_min_support': combo['apriori_params']['min_support'],\n",
    "            'apriori_min_confidence': combo['apriori_params']['min_confidence'],\n",
    "            'word2vec_vector_size': combo['word2vec_params']['vector_size'],\n",
    "            'word2vec_window': combo['word2vec_params']['window'],\n",
    "            'word2vec_min_count': combo['word2vec_params']['min_count'],\n",
    "            'word2vec_similarity_threshold': combo['word2vec_params']['similarity_threshold'],\n",
    "            'execution_time': execution_time,\n",
    "            **metrics\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'combination_id': combo['combination_id'],\n",
    "            'error': str(e),\n",
    "            'agreement_rate': 0,\n",
    "            'total_pairs': 0,\n",
    "            'execution_time': time.time() - start_time\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d64698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaximumAgreementGridSearch:\n",
    "    \"\"\"\n",
    "    Grid Search for Maximum Agreement Analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_path, excel_file, use_subset=True):\n",
    "        \"\"\"\n",
    "        Initialize with data preprocessing and encoding optimization\n",
    "        \"\"\"\n",
    "        print(\"=\"*90)\n",
    "        print(\"MAXIMUM AGREEMENT GRID SEARCH ANALYSIS\")\n",
    "        print(\"=\"*90)\n",
    "        print(\"Phase 1.1: Data Preparation\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        self.excel_file = excel_file\n",
    "        self.file_path = os.path.join(data_path, excel_file)\n",
    "        self.use_subset = use_subset\n",
    "        \n",
    "        print(f\"Loading dataset from: {self.file_path}\")\n",
    "        self.data_excel = pd.read_excel(self.file_path)\n",
    "        print(f\"Raw dataset shape: {self.data_excel.shape}\")\n",
    "        \n",
    "        \n",
    "        original_size = len(self.data_excel)\n",
    "        self.data_excel = self.data_excel[self.data_excel['category'] != 'Miscellaneous']\n",
    "        self.data_excel.dropna(subset=['Itemname'], inplace=True)\n",
    "        print(f\"Filtered dataset: {len(self.data_excel)} rows ({original_size - len(self.data_excel)} removed)\")\n",
    "        \n",
    "        \n",
    "        self.basket = self.data_excel.groupby('BillNo')['Itemname'].apply(list)\n",
    "        self.transactions = self.basket.values.tolist()\n",
    "        \n",
    "        \n",
    "        if self.use_subset:\n",
    "            subset_size = len(self.transactions) // 3\n",
    "            self.transactions = self.transactions[:subset_size]\n",
    "            print(f\"Using subset: {len(self.transactions)} transactions (first third of data)\")\n",
    "        \n",
    "        self.unique_products = sorted(self.data_excel['Itemname'].unique().tolist())\n",
    "        self.product_categories = dict(zip(\n",
    "            self.data_excel['Itemname'], \n",
    "            self.data_excel['category']\n",
    "        ))\n",
    "        \n",
    "        \n",
    "        print(\"Pre-computing transaction encodings...\")\n",
    "        self.te = TransactionEncoder()\n",
    "        self.te_ary = self.te.fit(self.transactions).transform(self.transactions)\n",
    "        self.basket_encoded = pd.DataFrame(self.te_ary, columns=self.te.columns_)\n",
    "        print(f\"✓ Transaction encoding completed: {self.basket_encoded.shape}\")\n",
    "        \n",
    "        \n",
    "        self.grid_search_results = []\n",
    "        self.best_agreement_params = None\n",
    "        self.best_agreement_score = 0\n",
    "        self.optimal_params = None\n",
    "        \n",
    "        avg_transaction_size = np.mean([len(t) for t in self.transactions])\n",
    "        unique_categories = self.data_excel['category'].nunique()\n",
    "        \n",
    "        print(f\"✓ Transactions: {len(self.transactions)}\")\n",
    "        print(f\"✓ Unique products: {len(self.unique_products)}\")\n",
    "        print(f\"✓ Product categories: {unique_categories}\")\n",
    "        print(f\"✓ Average transaction size: {avg_transaction_size:.2f}\")\n",
    "        print(\"✓ Pre-computed encodings ready\")\n",
    "        \n",
    "    def define_parameter_search_space(self):\n",
    "        \"\"\"\n",
    "        Define parameter search space\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*90)\n",
    "        print(\"Phase 1.2: Define Parameter Search Space\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        self.apriori_params = {\n",
    "            'min_support': [0.01, 0.05, 0.1],      \n",
    "            'min_confidence': [0.1, 0.3, 0.5]       \n",
    "        }\n",
    "        \n",
    "        self.word2vec_params = {\n",
    "            'vector_size': [50, 100, 300],           \n",
    "            'window': [3, 5, 10],                      \n",
    "            'min_count': [5, 10, 20],                     \n",
    "            'similarity_threshold': [0.1, 0.2, 0.5] \n",
    "        }\n",
    "        \n",
    "        \n",
    "        apriori_combinations = len(list(product(*self.apriori_params.values())))\n",
    "        word2vec_combinations = len(list(product(*self.word2vec_params.values())))\n",
    "        total_combinations = apriori_combinations * word2vec_combinations\n",
    "        \n",
    "        print(\"APRIORI PARAMETER SPACE:\")\n",
    "        for param, values in self.apriori_params.items():\n",
    "            print(f\"   {param}: {values}\")\n",
    "        print(f\"   → {apriori_combinations} combinations\")\n",
    "        \n",
    "        print(\"\\nWORD2VEC PARAMETER SPACE:\")\n",
    "        for param, values in self.word2vec_params.items():\n",
    "            print(f\"   {param}: {values}\")\n",
    "        print(f\"   → {word2vec_combinations} combinations\")\n",
    "        \n",
    "        print(f\"\\nTOTAL GRID SEARCH COMBINATIONS: {total_combinations}\")\n",
    "        \n",
    "        \n",
    "        self.param_combinations = []\n",
    "        combination_id = 0\n",
    "        for support, confidence in product(*self.apriori_params.values()):\n",
    "            for vector_size, window, min_count, sim_threshold in product(*self.word2vec_params.values()):\n",
    "                combination_id += 1\n",
    "                self.param_combinations.append({\n",
    "                    'combination_id': combination_id,\n",
    "                    'apriori_params': {'min_support': support, 'min_confidence': confidence},\n",
    "                    'word2vec_params': {\n",
    "                        'vector_size': vector_size,\n",
    "                        'window': window,\n",
    "                        'min_count': min_count,\n",
    "                        'similarity_threshold': sim_threshold\n",
    "                    }\n",
    "                })\n",
    "        \n",
    "        print(f\"Prepared {len(self.param_combinations)} parameter combinations\")\n",
    "        print(\"Phase 1.2 Complete: Parameter search space defined\")\n",
    "        return total_combinations\n",
    "    \n",
    "    def run_grid_search(self):\n",
    "        \"\"\"\n",
    "        Run grid search sequentially\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*90)\n",
    "        print(\"Phase 2.2: Sequential Grid Search Implementation\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        total_combinations = self.define_parameter_search_space()\n",
    "        \n",
    "        print(f\"Starting sequential processing...\")\n",
    "        print(\"Focus: Finding maximum agreement on complementary product pairs\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for i, combo in enumerate(self.param_combinations, 1):\n",
    "            try:\n",
    "                result = process_single_combination(\n",
    "                    combo,\n",
    "                    self.basket_encoded.values,\n",
    "                    self.basket_encoded.columns.tolist(),\n",
    "                    self.transactions\n",
    "                )\n",
    "                \n",
    "                self.grid_search_results.append(result)\n",
    "                \n",
    "                \n",
    "                if 'error' not in result and result['agreement_rate'] > self.best_agreement_score:\n",
    "                    self.best_agreement_score = result['agreement_rate']\n",
    "                    self.best_agreement_params = result.copy()\n",
    "                \n",
    "                \n",
    "                if i % 10 == 0:\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                    avg_time_per_combo = elapsed_time / i\n",
    "                    remaining_combos = total_combinations - i\n",
    "                    estimated_remaining = avg_time_per_combo * remaining_combos\n",
    "                    \n",
    "                    print(f\"Progress: {i}/{total_combinations} \"\n",
    "                          f\"({i/total_combinations*100:.1f}%) \"\n",
    "                          f\"Best agreement so far: {self.best_agreement_score:.3f} \"\n",
    "                          f\"Est. remaining time: {estimated_remaining/60:.1f} min\")\n",
    "                \n",
    "            except Exception as exc:\n",
    "                print(f'Combination {combo[\"combination_id\"]} generated an exception: {exc}')\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\nPhase 2.2 Complete: Tested {total_combinations} parameter combinations\")\n",
    "        print(f\"Total execution time: {total_time/60:.2f} minutes\")\n",
    "        print(f\"Average time per combination: {total_time/total_combinations:.2f} seconds\")\n",
    "        print(f\"Maximum agreement found: {self.best_agreement_score:.3f}\")\n",
    "    \n",
    "    def analyze_optimal_parameters(self):\n",
    "        \"\"\"\n",
    "        Analyze optimal parameters\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*90)\n",
    "        print(\"Phase 2.3 & 3: Optimal Parameter Analysis\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        if not self.grid_search_results:\n",
    "            print(\"ERROR: No grid search results found. Run grid search first.\")\n",
    "            return None\n",
    "        \n",
    "        \n",
    "        valid_results = [r for r in self.grid_search_results if 'error' not in r]\n",
    "        \n",
    "        if not valid_results:\n",
    "            print(\"ERROR: No valid results found. All combinations failed.\")\n",
    "            return None\n",
    "        \n",
    "        results_df = pd.DataFrame(valid_results)\n",
    "        top_5 = results_df.nlargest(5, 'agreement_rate')\n",
    "        \n",
    "        print(\"TOP 5 PARAMETER COMBINATIONS BY AGREEMENT RATE:\")\n",
    "        print(\"=\" * 70)\n",
    "        for i, (_, row) in enumerate(top_5.iterrows(), 1):\n",
    "            print(f\"\\nRANK {i}: Agreement Rate = {row['agreement_rate']:.4f}\")\n",
    "            print(f\"   Apriori: support={row['apriori_min_support']}, confidence={row['apriori_min_confidence']}\")\n",
    "            print(f\"   Word2Vec: vector={row['word2vec_vector_size']}, window={row['word2vec_window']}\")\n",
    "            print(f\"             min_count={row['word2vec_min_count']}, similarity={row['word2vec_similarity_threshold']}\")\n",
    "            print(f\"   Pairs: {row['agreed_pairs']} agreed, {row['apriori_pairs']} Apriori, {row['word2vec_pairs']} Word2Vec\")\n",
    "            print(f\"   Execution time: {row['execution_time']:.2f} seconds\")\n",
    "        \n",
    "        optimal = top_5.iloc[0]\n",
    "        self.optimal_params = {\n",
    "            'apriori': {\n",
    "                'min_support': optimal['apriori_min_support'],\n",
    "                'min_confidence': optimal['apriori_min_confidence']\n",
    "            },\n",
    "            'word2vec': {\n",
    "                'vector_size': int(optimal['word2vec_vector_size']),\n",
    "                'window': int(optimal['word2vec_window']),\n",
    "                'min_count': int(optimal['word2vec_min_count']),\n",
    "                'similarity_threshold': optimal['word2vec_similarity_threshold']\n",
    "            },\n",
    "            'performance': {\n",
    "                'agreement_rate': optimal['agreement_rate'],\n",
    "                'agreed_pairs': int(optimal['agreed_pairs']),\n",
    "                'total_pairs': int(optimal['total_pairs'])\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nOPTIMAL PARAMETERS SELECTED:\")\n",
    "        print(f\"Agreement Rate: {optimal['agreement_rate']:.4f}\")\n",
    "        print(f\"Agreed Pairs: {optimal['agreed_pairs']}\")\n",
    "        \n",
    "        \n",
    "        total_time = sum(result['execution_time'] for result in valid_results)\n",
    "        print(f\"\\nPERFORMANCE SUMMARY:\")\n",
    "        print(f\"Total combinations tested: {len(valid_results)}\")\n",
    "        print(f\"Failed combinations: {len(self.grid_search_results) - len(valid_results)}\")\n",
    "        print(f\"Total execution time: {total_time/60:.2f} minutes\")\n",
    "        print(f\"Average time per combination: {total_time/len(valid_results):.2f} seconds\")\n",
    "        \n",
    "        return optimal\n",
    "    \n",
    "    def save_results(self):\n",
    "        \"\"\"\n",
    "        Save results\n",
    "        \"\"\"\n",
    "        if self.optimal_params is None:\n",
    "            print(\"ERROR: No optimal parameters to save. Run analysis first.\")\n",
    "            return\n",
    "        \n",
    "        os.makedirs(path_results, exist_ok=True)\n",
    "        \n",
    "        \n",
    "        with open(os.path.join(path_results, 'maximum_agreement_optimal_parameters.json'), 'w') as f:\n",
    "            json.dump(self.optimal_params, f, indent=2)\n",
    "        \n",
    "        \n",
    "        results_df = pd.DataFrame(self.grid_search_results)\n",
    "        results_df.to_csv(os.path.join(path_results, 'maximum_agreement_grid_search_results.csv'), index=False)\n",
    "        \n",
    "        \n",
    "        valid_results = [r for r in self.grid_search_results if 'error' not in r]\n",
    "        total_time = sum(result['execution_time'] for result in valid_results)\n",
    "        \n",
    "        summary = {\n",
    "            'analysis_details': {\n",
    "                'used_data_subset': self.use_subset,\n",
    "                'subset_size': len(self.transactions),\n",
    "                'pre_computed_encodings': True,\n",
    "                'processing_type': 'sequential'\n",
    "            },\n",
    "            'performance_metrics': {\n",
    "                'total_combinations': len(self.grid_search_results),\n",
    "                'valid_combinations': len(valid_results),\n",
    "                'failed_combinations': len(self.grid_search_results) - len(valid_results),\n",
    "                'total_execution_time_minutes': total_time / 60,\n",
    "                'average_time_per_combination_seconds': total_time / len(valid_results) if valid_results else 0\n",
    "            },\n",
    "            'optimal_results': self.optimal_params\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(path_results, 'analysis_summary.json'), 'w') as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        \n",
    "        print(\"Results saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6e14a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIALIZING MAXIMUM AGREEMENT GRID SEARCH\n",
      "==========================================================================================\n",
      "==========================================================================================\n",
      "MAXIMUM AGREEMENT GRID SEARCH ANALYSIS\n",
      "==========================================================================================\n",
      "Phase 1.1: Data Preparation\n",
      "--------------------------------------------------\n",
      "Loading dataset from: c:\\Users\\moham\\Coding-Projects\\Apriori_VS_Word2Vec\\Dataset\\full_validated_dataset.xlsx\n",
      "Raw dataset shape: (520609, 8)\n",
      "Filtered dataset: 517587 rows (3022 removed)\n",
      "Using subset: 6501 transactions (first third of data)\n",
      "Pre-computing transaction encodings...\n",
      "✓ Transaction encoding completed: (6501, 3235)\n",
      "✓ Transactions: 6501\n",
      "✓ Unique products: 4009\n",
      "✓ Product categories: 19\n",
      "✓ Average transaction size: 25.78\n",
      "✓ Pre-computed encodings ready\n",
      "\n",
      "==========================================================================================\n",
      "Phase 2.2: Sequential Grid Search Implementation\n",
      "--------------------------------------------------\n",
      "\n",
      "==========================================================================================\n",
      "Phase 1.2: Define Parameter Search Space\n",
      "--------------------------------------------------\n",
      "APRIORI PARAMETER SPACE:\n",
      "   min_support: [0.01, 0.05, 0.1]\n",
      "   min_confidence: [0.1, 0.3, 0.5]\n",
      "   → 9 combinations\n",
      "\n",
      "WORD2VEC PARAMETER SPACE:\n",
      "   vector_size: [50, 100, 300]\n",
      "   window: [3, 5, 10]\n",
      "   min_count: [5, 10, 20]\n",
      "   similarity_threshold: [0.1, 0.2, 0.5]\n",
      "   → 81 combinations\n",
      "\n",
      "TOTAL GRID SEARCH COMBINATIONS: 729\n",
      "Prepared 729 parameter combinations\n",
      "Phase 1.2 Complete: Parameter search space defined\n",
      "Starting sequential processing...\n",
      "Focus: Finding maximum agreement on complementary product pairs\n",
      "Progress: 10/729 (1.4%) Best agreement so far: 0.004 Est. remaining time: 620.4 min\n",
      "Progress: 20/729 (2.7%) Best agreement so far: 0.006 Est. remaining time: 606.6 min\n",
      "Progress: 30/729 (4.1%) Best agreement so far: 0.008 Est. remaining time: 602.0 min\n",
      "Progress: 40/729 (5.5%) Best agreement so far: 0.008 Est. remaining time: 587.3 min\n",
      "Progress: 50/729 (6.9%) Best agreement so far: 0.008 Est. remaining time: 580.1 min\n",
      "Progress: 60/729 (8.2%) Best agreement so far: 0.008 Est. remaining time: 577.9 min\n",
      "Progress: 70/729 (9.6%) Best agreement so far: 0.008 Est. remaining time: 569.8 min\n",
      "Progress: 80/729 (11.0%) Best agreement so far: 0.008 Est. remaining time: 563.9 min\n",
      "Progress: 90/729 (12.3%) Best agreement so far: 0.008 Est. remaining time: 549.3 min\n",
      "Progress: 100/729 (13.7%) Best agreement so far: 0.008 Est. remaining time: 538.5 min\n",
      "Progress: 110/729 (15.1%) Best agreement so far: 0.008 Est. remaining time: 529.0 min\n",
      "Progress: 120/729 (16.5%) Best agreement so far: 0.008 Est. remaining time: 518.2 min\n",
      "Progress: 130/729 (17.8%) Best agreement so far: 0.008 Est. remaining time: 513.7 min\n",
      "Progress: 140/729 (19.2%) Best agreement so far: 0.008 Est. remaining time: 505.9 min\n",
      "Progress: 150/729 (20.6%) Best agreement so far: 0.008 Est. remaining time: 498.0 min\n",
      "Progress: 160/729 (21.9%) Best agreement so far: 0.008 Est. remaining time: 490.2 min\n",
      "Progress: 170/729 (23.3%) Best agreement so far: 0.008 Est. remaining time: 479.3 min\n",
      "Progress: 180/729 (24.7%) Best agreement so far: 0.008 Est. remaining time: 469.5 min\n",
      "Progress: 190/729 (26.1%) Best agreement so far: 0.008 Est. remaining time: 460.7 min\n",
      "Progress: 200/729 (27.4%) Best agreement so far: 0.008 Est. remaining time: 451.9 min\n",
      "Progress: 210/729 (28.8%) Best agreement so far: 0.008 Est. remaining time: 443.5 min\n",
      "Progress: 220/729 (30.2%) Best agreement so far: 0.008 Est. remaining time: 435.4 min\n",
      "Progress: 230/729 (31.6%) Best agreement so far: 0.008 Est. remaining time: 428.4 min\n",
      "Progress: 240/729 (32.9%) Best agreement so far: 0.008 Est. remaining time: 422.8 min\n",
      "Progress: 250/729 (34.3%) Best agreement so far: 0.008 Est. remaining time: 407.1 min\n",
      "Progress: 260/729 (35.7%) Best agreement so far: 0.008 Est. remaining time: 389.6 min\n",
      "Progress: 270/729 (37.0%) Best agreement so far: 0.008 Est. remaining time: 376.8 min\n",
      "Progress: 280/729 (38.4%) Best agreement so far: 0.008 Est. remaining time: 361.6 min\n",
      "Progress: 290/729 (39.8%) Best agreement so far: 0.008 Est. remaining time: 347.6 min\n",
      "Progress: 300/729 (41.2%) Best agreement so far: 0.008 Est. remaining time: 334.3 min\n",
      "Progress: 310/729 (42.5%) Best agreement so far: 0.008 Est. remaining time: 321.7 min\n",
      "Progress: 320/729 (43.9%) Best agreement so far: 0.008 Est. remaining time: 309.8 min\n",
      "Progress: 330/729 (45.3%) Best agreement so far: 0.008 Est. remaining time: 297.9 min\n",
      "Progress: 340/729 (46.6%) Best agreement so far: 0.008 Est. remaining time: 286.2 min\n",
      "Progress: 350/729 (48.0%) Best agreement so far: 0.008 Est. remaining time: 278.3 min\n",
      "Progress: 360/729 (49.4%) Best agreement so far: 0.008 Est. remaining time: 267.3 min\n",
      "Progress: 370/729 (50.8%) Best agreement so far: 0.008 Est. remaining time: 257.1 min\n",
      "Progress: 380/729 (52.1%) Best agreement so far: 0.008 Est. remaining time: 247.3 min\n",
      "Progress: 390/729 (53.5%) Best agreement so far: 0.008 Est. remaining time: 237.8 min\n",
      "Progress: 400/729 (54.9%) Best agreement so far: 0.008 Est. remaining time: 228.7 min\n",
      "Progress: 410/729 (56.2%) Best agreement so far: 0.008 Est. remaining time: 219.6 min\n",
      "Progress: 420/729 (57.6%) Best agreement so far: 0.008 Est. remaining time: 210.3 min\n",
      "Progress: 430/729 (59.0%) Best agreement so far: 0.008 Est. remaining time: 207.1 min\n",
      "Progress: 440/729 (60.4%) Best agreement so far: 0.008 Est. remaining time: 198.0 min\n",
      "Progress: 450/729 (61.7%) Best agreement so far: 0.008 Est. remaining time: 189.2 min\n",
      "Progress: 460/729 (63.1%) Best agreement so far: 0.008 Est. remaining time: 180.9 min\n",
      "Progress: 470/729 (64.5%) Best agreement so far: 0.008 Est. remaining time: 172.9 min\n",
      "Progress: 480/729 (65.8%) Best agreement so far: 0.008 Est. remaining time: 165.1 min\n",
      "Progress: 490/729 (67.2%) Best agreement so far: 0.008 Est. remaining time: 157.2 min\n",
      "Progress: 500/729 (68.6%) Best agreement so far: 0.008 Est. remaining time: 154.5 min\n",
      "Progress: 510/729 (70.0%) Best agreement so far: 0.008 Est. remaining time: 146.6 min\n",
      "Progress: 520/729 (71.3%) Best agreement so far: 0.008 Est. remaining time: 138.7 min\n",
      "Progress: 530/729 (72.7%) Best agreement so far: 0.008 Est. remaining time: 130.9 min\n",
      "Progress: 540/729 (74.1%) Best agreement so far: 0.008 Est. remaining time: 123.4 min\n",
      "Progress: 550/729 (75.4%) Best agreement so far: 0.008 Est. remaining time: 116.2 min\n",
      "Progress: 560/729 (76.8%) Best agreement so far: 0.008 Est. remaining time: 109.1 min\n",
      "Progress: 570/729 (78.2%) Best agreement so far: 0.008 Est. remaining time: 102.1 min\n",
      "Progress: 580/729 (79.6%) Best agreement so far: 0.008 Est. remaining time: 98.7 min\n",
      "Progress: 590/729 (80.9%) Best agreement so far: 0.008 Est. remaining time: 91.4 min\n",
      "Progress: 600/729 (82.3%) Best agreement so far: 0.008 Est. remaining time: 84.3 min\n",
      "Progress: 610/729 (83.7%) Best agreement so far: 0.008 Est. remaining time: 77.2 min\n",
      "Progress: 620/729 (85.0%) Best agreement so far: 0.008 Est. remaining time: 70.2 min\n",
      "Progress: 630/729 (86.4%) Best agreement so far: 0.008 Est. remaining time: 63.4 min\n",
      "Progress: 640/729 (87.8%) Best agreement so far: 0.008 Est. remaining time: 56.7 min\n",
      "Progress: 650/729 (89.2%) Best agreement so far: 0.008 Est. remaining time: 50.2 min\n",
      "Progress: 660/729 (90.5%) Best agreement so far: 0.008 Est. remaining time: 45.4 min\n",
      "Progress: 670/729 (91.9%) Best agreement so far: 0.008 Est. remaining time: 38.6 min\n",
      "Progress: 680/729 (93.3%) Best agreement so far: 0.008 Est. remaining time: 31.9 min\n",
      "Progress: 690/729 (94.7%) Best agreement so far: 0.008 Est. remaining time: 25.2 min\n",
      "Progress: 700/729 (96.0%) Best agreement so far: 0.008 Est. remaining time: 18.6 min\n",
      "Progress: 710/729 (97.4%) Best agreement so far: 0.008 Est. remaining time: 12.1 min\n",
      "Progress: 720/729 (98.8%) Best agreement so far: 0.008 Est. remaining time: 5.7 min\n",
      "\n",
      "Phase 2.2 Complete: Tested 729 parameter combinations\n",
      "Total execution time: 462.31 minutes\n",
      "Average time per combination: 38.05 seconds\n",
      "Maximum agreement found: 0.008\n",
      "\n",
      "==========================================================================================\n",
      "Phase 2.3 & 3: Optimal Parameter Analysis\n",
      "--------------------------------------------------\n",
      "TOP 5 PARAMETER COMBINATIONS BY AGREEMENT RATE:\n",
      "======================================================================\n",
      "\n",
      "RANK 1: Agreement Rate = 0.0079\n",
      "   Apriori: support=0.01, confidence=0.1\n",
      "   Word2Vec: vector=50, window=10\n",
      "             min_count=20, similarity=0.5\n",
      "   Pairs: 506 agreed, 1129 Apriori, 63498 Word2Vec\n",
      "   Execution time: 39.50 seconds\n",
      "\n",
      "RANK 2: Agreement Rate = 0.0069\n",
      "   Apriori: support=0.01, confidence=0.1\n",
      "   Word2Vec: vector=100, window=10\n",
      "             min_count=20, similarity=0.5\n",
      "   Pairs: 292 agreed, 1129 Apriori, 41721 Word2Vec\n",
      "   Execution time: 49.32 seconds\n",
      "\n",
      "RANK 3: Agreement Rate = 0.0065\n",
      "   Apriori: support=0.01, confidence=0.3\n",
      "   Word2Vec: vector=100, window=10\n",
      "             min_count=20, similarity=0.5\n",
      "   Pairs: 276 agreed, 593 Apriori, 42001 Word2Vec\n",
      "   Execution time: 47.57 seconds\n",
      "\n",
      "RANK 4: Agreement Rate = 0.0065\n",
      "   Apriori: support=0.01, confidence=0.3\n",
      "   Word2Vec: vector=50, window=10\n",
      "             min_count=20, similarity=0.5\n",
      "   Pairs: 412 agreed, 593 Apriori, 63497 Word2Vec\n",
      "   Execution time: 41.34 seconds\n",
      "\n",
      "RANK 5: Agreement Rate = 0.0062\n",
      "   Apriori: support=0.01, confidence=0.1\n",
      "   Word2Vec: vector=300, window=10\n",
      "             min_count=20, similarity=0.5\n",
      "   Pairs: 266 agreed, 1129 Apriori, 41912 Word2Vec\n",
      "   Execution time: 43.34 seconds\n",
      "\n",
      "OPTIMAL PARAMETERS SELECTED:\n",
      "Agreement Rate: 0.0079\n",
      "Agreed Pairs: 506\n",
      "\n",
      "PERFORMANCE SUMMARY:\n",
      "Total combinations tested: 729\n",
      "Failed combinations: 0\n",
      "Total execution time: 462.12 minutes\n",
      "Average time per combination: 38.03 seconds\n",
      "Results saved successfully!\n",
      "\n",
      "==========================================================================================\n",
      "ANALYSIS PIPELINE COMPLETED SUCCESSFULLY!\n",
      "==========================================================================================\n",
      "Sequential processing completed.\n",
      "All results have been saved to the Results directory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"INITIALIZING MAXIMUM AGREEMENT GRID SEARCH\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "try:\n",
    "    \n",
    "    analyzer = MaximumAgreementGridSearch(path, excel_file, use_subset=True)\n",
    "    \n",
    "    \n",
    "    analyzer.run_grid_search()\n",
    "    \n",
    "    \n",
    "    optimal_results = analyzer.analyze_optimal_parameters()\n",
    "    \n",
    "    if optimal_results is not None:\n",
    "        \n",
    "        analyzer.save_results()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*90)\n",
    "        print(\"ANALYSIS PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"=\"*90)\n",
    "        print(\"Sequential processing completed.\")\n",
    "        print(\"All results have been saved to the Results directory.\")\n",
    "    else:\n",
    "        print(\"Analysis failed - no valid results found.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error in main execution: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
