{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apriori vs Word2Vec Model Comparison\n",
    "\n",
    "This notebook compares the performance of Apriori and Word2Vec models for detecting complementary products in market basket analysis. The comparison includes:\n",
    "\n",
    "- Execution time and memory usage\n",
    "- Coverage and diversity metrics\n",
    "- Clustering quality \n",
    "- Visualization of key metrics\n",
    "\n",
    "The `ModelEvaluator` class handles the evaluation process, including model training, metric calculation, and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import tracemalloc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from gensim.models import Word2Vec\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# File path settings\n",
    "path = r'C:\\Users\\moham\\Apriori_VS_Word2Vec\\Dataset'\n",
    "path_results = r'C:\\Users\\moham\\Apriori_VS_Word2Vec\\Results'\n",
    "excel_file = 'df_merged_items_category.xlsx'\n",
    "\n",
    "# Apriori parameters\n",
    "apriori_min_support = 0.01\n",
    "apriori_min_confidence = 0.05\n",
    "apriori_min_lift = 1.2\n",
    "\n",
    "# Word2Vec parameters\n",
    "vector_size_num = 100\n",
    "window_num = 5\n",
    "workers_num = 4\n",
    "negative_sampling = 10\n",
    "epoches_num = 10\n",
    "min_count = 2\n",
    "w2v_min_count = 2\n",
    "w2v_topn = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelEvaluator Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ModelEvaluator:\n",
    "    \"\"\"\n",
    "    Class to evaluate and compare Apriori and Word2Vec models across multiple metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_path, path_results, excel_file, data_subset=None, subset_name=\"whole\"):\n",
    "        \"\"\"\n",
    "        Initialize with dataset path and optional data subset.\n",
    "        \n",
    "        Args:\n",
    "            data_path (str): Path to the data directory\n",
    "            path_results (str): Path to save results\n",
    "            excel_file (str): Name of the Excel file containing transaction data\n",
    "            data_subset (DataFrame, optional): Subset of data to use instead of loading from file\n",
    "            subset_name (str): Name of the data subset (e.g., \"whole\", \"first_third\", \"last_two_thirds\")\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.path_results = path_results\n",
    "        self.excel_file = excel_file\n",
    "        self.file_path = os.path.join(data_path, excel_file)\n",
    "        self.subset_name = subset_name\n",
    "        self.metrics = {\n",
    "            'apriori': {},\n",
    "            'word2vec': {}\n",
    "        }\n",
    "        \n",
    "        # Load dataset or use provided subset\n",
    "        if data_subset is not None:\n",
    "            self.data_excel = data_subset.copy()\n",
    "        else:\n",
    "            self.data_excel = pd.read_excel(self.file_path)\n",
    "        \n",
    "        self.data_excel.dropna(subset=['Itemname'], inplace=True)\n",
    "        \n",
    "        # Create transaction baskets\n",
    "        self.basket = self.data_excel.groupby('BillNo')['Itemname'].apply(list)\n",
    "        self.transactions = self.basket.values.tolist()\n",
    "        self.unique_products = self.data_excel['Itemname'].unique().tolist()\n",
    "        \n",
    "        # Create product to category mapping if category column exists\n",
    "        self.product_to_category = {}\n",
    "        if 'category' in self.data_excel.columns:\n",
    "            # Create a mapping from product name to category\n",
    "            product_category_mapping = self.data_excel[['Itemname', 'category']].drop_duplicates()\n",
    "            self.product_to_category = dict(zip(product_category_mapping['Itemname'], product_category_mapping['category']))\n",
    "        \n",
    "        # Initialize result dataframes\n",
    "        self.apriori_rules = None\n",
    "        self.word2vec_complementary = None\n",
    "        \n",
    "        print(f\"Dataset loaded for {subset_name} with {len(self.basket)} transactions and {len(self.unique_products)} unique products\")\n",
    "        \n",
    "    def run_apriori(self, min_support=apriori_min_support, min_confidence=apriori_min_confidence, min_lift=apriori_min_lift):\n",
    "        \"\"\"\n",
    "        Run Apriori algorithm and measure performance.\n",
    "        \n",
    "        Args:\n",
    "            min_support (float): Minimum support threshold\n",
    "            min_confidence (float): Minimum confidence threshold\n",
    "            min_lift (float): Minimum lift threshold\n",
    "            \n",
    "        Returns:\n",
    "            dict: Performance metrics for Apriori\n",
    "        \"\"\"\n",
    "        print(f\"Running Apriori algorithm for {self.subset_name}...\")\n",
    "        \n",
    "        # Convert transactions to binary format\n",
    "        te = TransactionEncoder()\n",
    "        te_ary = te.fit(self.transactions).transform(self.transactions)\n",
    "        basket_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "        \n",
    "        # Start the process and memory measurement\n",
    "        tracemalloc.start()\n",
    "        start_memory = tracemalloc.get_traced_memory()[1]  # Initial memory usage\n",
    "        start_time = time.time()\n",
    "\n",
    "        print(f\"Apriori started with {start_memory} bytes memory used\")\n",
    "\n",
    "        # Generate frequent itemsets\n",
    "        frequent_itemsets = apriori(basket_encoded, min_support=min_support, use_colnames=True)\n",
    "\n",
    "        # Generate association rules\n",
    "        rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=min_lift)\n",
    "        rules = rules[rules['confidence'] >= min_confidence]\n",
    "\n",
    "        # Add antecedent length column\n",
    "        rules[\"antecedent_len\"] = rules[\"antecedents\"].apply(lambda x: len(x))\n",
    "\n",
    "        # End time and memory measurement\n",
    "        end_time = time.time()\n",
    "        current_memory = tracemalloc.get_traced_memory()[1]\n",
    "        peak_memory = (current_memory - start_memory) / (1024 * 1024)  # Convert to MB\n",
    "        tracemalloc.stop()\n",
    "        print(f\"Apriori ended with {peak_memory} MB memory used\")\n",
    "        \n",
    "        self.apriori_rules = rules\n",
    "        \n",
    "        # Convert Apriori rules to product pairs with categories\n",
    "        self.apriori_product_pairs = self.convert_apriori_rules_to_pairs(rules)\n",
    "        \n",
    "        # Store metrics\n",
    "        self.metrics['apriori'] = {\n",
    "            'execution_time': end_time - start_time,\n",
    "            'memory_usage': peak_memory,\n",
    "            'num_rules': len(rules),\n",
    "            'coverage': self.calculate_apriori_coverage(rules),\n",
    "            'diversity': self.calculate_apriori_diversity(rules),\n",
    "        }\n",
    "        \n",
    "        print(f\"Apriori completed for {self.subset_name} with {len(rules)} rules generated\")\n",
    "        return self.metrics['apriori']\n",
    "    \n",
    "    def convert_apriori_rules_to_pairs(self, apriori_rules):\n",
    "        \"\"\"\n",
    "        Convert Apriori rules to a consistent product pairs table with category information.\n",
    "        \n",
    "        Args:\n",
    "            apriori_rules (DataFrame): DataFrame containing Apriori rules\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame: Consistent format with one product pair per row and category information\n",
    "        \"\"\"\n",
    "        product_pairs = []\n",
    "        \n",
    "        for _, rule in apriori_rules.iterrows():\n",
    "            # In pandas, frozenset is maintained as is\n",
    "            antecedents = list(rule['antecedents'])\n",
    "            consequents = list(rule['consequents'])\n",
    "            \n",
    "            # For each combination of antecedent and consequent\n",
    "            for antecedent in antecedents:\n",
    "                for consequent in consequents:\n",
    "                    # Skip if same product\n",
    "                    if antecedent == consequent:\n",
    "                        continue\n",
    "                    \n",
    "                    # Create a pair\n",
    "                    pair = {\n",
    "                        'Original Product': antecedent,\n",
    "                        'Complementary Product': consequent,\n",
    "                        'Confidence': rule['confidence'],\n",
    "                        'Lift': rule['lift'],\n",
    "                        'Support': rule['support']\n",
    "                    }\n",
    "                    \n",
    "                    # Add category information if available\n",
    "                    if self.product_to_category:\n",
    "                        if antecedent in self.product_to_category:\n",
    "                            pair['Original Product category'] = self.product_to_category[antecedent]\n",
    "                        else:\n",
    "                            pair['Original Product category'] = 'Unknown'\n",
    "                            \n",
    "                        if consequent in self.product_to_category:\n",
    "                            pair['Complementary Product category'] = self.product_to_category[consequent]\n",
    "                        else:\n",
    "                            pair['Complementary Product category'] = 'Unknown'\n",
    "                    \n",
    "                    product_pairs.append(pair)\n",
    "        \n",
    "        return pd.DataFrame(product_pairs)\n",
    "\n",
    "    def run_word2vec(self, vector_size=vector_size_num, window=window_num, min_count=min_count, topn=w2v_topn):\n",
    "        \"\"\"\n",
    "        Run Word2Vec model and measure performance.\n",
    "        \n",
    "        Args:\n",
    "            vector_size (int): Dimensionality of word vectors\n",
    "            window (int): Context window size\n",
    "            min_count (int): Minimum word frequency\n",
    "            topn (int): Number of top complementary products to generate\n",
    "            \n",
    "        Returns:\n",
    "            dict: Performance metrics for Word2Vec\n",
    "        \"\"\"\n",
    "        print(f\"Running Word2Vec model for {self.subset_name}...\")\n",
    "        \n",
    "        # Start the process and memory measurement\n",
    "        tracemalloc.start()\n",
    "        start_memory = tracemalloc.get_traced_memory()[1]  # Initial memory usage\n",
    "        start_time = time.time()\n",
    "\n",
    "        print(f\"Word2Vec started with {start_memory} bytes memory used\")\n",
    "\n",
    "        # Train Word2Vec model\n",
    "        model = Word2Vec(\n",
    "            sentences=self.transactions,\n",
    "            vector_size=vector_size_num,\n",
    "            window=window_num,\n",
    "            sg=1,  # Skip-gram model\n",
    "            negative=negative_sampling,  # Negative sampling\n",
    "            min_count=min_count,\n",
    "            workers=workers_num,\n",
    "            epochs=epoches_num\n",
    "        )\n",
    "        \n",
    "        # Generate complementary products\n",
    "        comprehensive_results = []\n",
    "        \n",
    "        # Dictionary to store model vocabulary for fast lookup\n",
    "        model_vocab = set(model.wv.index_to_key)\n",
    "        \n",
    "        for product in self.unique_products:\n",
    "            if product in model_vocab:\n",
    "                try:\n",
    "                    similar_products = model.wv.most_similar(product, topn=topn)\n",
    "                    \n",
    "                    complementary_list = [\n",
    "                        {\n",
    "                            'Original Product': product,\n",
    "                            'Complementary Product': comp_product,\n",
    "                            'Similarity Score': similarity,\n",
    "                            'Rank': rank + 1\n",
    "                        }\n",
    "                        for rank, (comp_product, similarity) in enumerate(similar_products)\n",
    "                    ]\n",
    "                    \n",
    "                    comprehensive_results.extend(complementary_list)\n",
    "                except KeyError:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        complementary_products_df = pd.DataFrame(comprehensive_results)\n",
    "        \n",
    "        # Add category information to Word2Vec results\n",
    "        if self.product_to_category and not complementary_products_df.empty:\n",
    "            # Add category for original product\n",
    "            complementary_products_df['Original Product category'] = complementary_products_df['Original Product'].apply(\n",
    "                lambda x: self.product_to_category.get(x, 'Unknown')\n",
    "            )\n",
    "            \n",
    "            # Add category for complementary product\n",
    "            complementary_products_df['Complementary Product category'] = complementary_products_df['Complementary Product'].apply(\n",
    "                lambda x: self.product_to_category.get(x, 'Unknown')\n",
    "            )\n",
    "        \n",
    "        # End time and memory measurement\n",
    "        end_time = time.time()\n",
    "        current_memory = tracemalloc.get_traced_memory()[1]\n",
    "        peak_memory = (current_memory - start_memory) / (1024 * 1024)  # Convert to MB\n",
    "        tracemalloc.stop()\n",
    "        print(f\"Word2Vec ended with {peak_memory} MB memory used\")\n",
    "        \n",
    "        self.word2vec_complementary = complementary_products_df\n",
    "        self.word2vec_model = model\n",
    "        \n",
    "        # Store metrics\n",
    "        self.metrics['word2vec'] = {\n",
    "            'execution_time': end_time - start_time,\n",
    "            'memory_usage': peak_memory,\n",
    "            'num_recommendations': len(complementary_products_df),\n",
    "            'coverage': self.calculate_word2vec_coverage(model, complementary_products_df),\n",
    "            'diversity': self.calculate_word2vec_diversity(complementary_products_df),\n",
    "        }\n",
    "        \n",
    "        print(f\"Word2Vec completed for {self.subset_name} with {len(complementary_products_df)} recommendations generated\")\n",
    "        return self.metrics['word2vec']\n",
    "    \n",
    "    def calculate_apriori_coverage(self, rules):\n",
    "        \"\"\"\n",
    "        Calculate coverage for Apriori rules.\n",
    "        \n",
    "        Args:\n",
    "            rules (DataFrame): Association rules\n",
    "            \n",
    "        Returns:\n",
    "            float: Coverage score\n",
    "        \"\"\"\n",
    "        unique_antecedents = set()\n",
    "        unique_consequents = set()\n",
    "        \n",
    "        for _, row in rules.iterrows():\n",
    "            antecedents = set(row['antecedents'])\n",
    "            consequents = set(row['consequents'])\n",
    "            \n",
    "            unique_antecedents.update(antecedents)\n",
    "            unique_consequents.update(consequents)\n",
    "        \n",
    "        unique_items = unique_antecedents.union(unique_consequents)\n",
    "        coverage = len(unique_items) / len(self.unique_products)\n",
    "        \n",
    "        return coverage\n",
    "    \n",
    "    def calculate_word2vec_coverage(self, model, complementary_df):\n",
    "        \"\"\"\n",
    "        Calculate coverage for Word2Vec model.\n",
    "        \n",
    "        Args:\n",
    "            model (Word2Vec): Trained Word2Vec model\n",
    "            complementary_df (DataFrame): Generated complementary products\n",
    "            \n",
    "        Returns:\n",
    "            float: Coverage score\n",
    "        \"\"\"\n",
    "        products_with_embeddings = complementary_df['Original Product'].nunique()\n",
    "        coverage = products_with_embeddings / len(self.unique_products)\n",
    "        \n",
    "        return coverage\n",
    "    \n",
    "    def calculate_apriori_diversity(self, rules):\n",
    "        \"\"\"\n",
    "        Calculate diversity for Apriori rules.\n",
    "        \n",
    "        Args:\n",
    "            rules (DataFrame): Association rules\n",
    "            \n",
    "        Returns:\n",
    "            float: Diversity score\n",
    "        \"\"\"\n",
    "        antecedent_consequents = {}\n",
    "        \n",
    "        for _, row in rules.iterrows():\n",
    "            antecedent = frozenset(row['antecedents'])\n",
    "            consequent = frozenset(row['consequents'])\n",
    "            \n",
    "            if antecedent in antecedent_consequents:\n",
    "                antecedent_consequents[antecedent].add(consequent)\n",
    "            else:\n",
    "                antecedent_consequents[antecedent] = {consequent}\n",
    "        \n",
    "        # Calculate average number of unique consequents per antecedent\n",
    "        if len(antecedent_consequents) > 0:\n",
    "            diversity = sum(len(consequents) for consequents in antecedent_consequents.values()) / len(antecedent_consequents)\n",
    "        else:\n",
    "            diversity = 0\n",
    "        \n",
    "        return diversity\n",
    "    \n",
    "    def calculate_word2vec_diversity(self, complementary_df):\n",
    "        # Group by original product\n",
    "        product_recommendations = {}\n",
    "        \n",
    "        for _, row in complementary_df.iterrows():\n",
    "            original_product = row['Original Product']\n",
    "            complementary_product = row['Complementary Product']\n",
    "            \n",
    "            if original_product in product_recommendations:\n",
    "                product_recommendations[original_product].add(complementary_product)\n",
    "            else:\n",
    "                product_recommendations[original_product] = {complementary_product}\n",
    "        \n",
    "        # Calculate average number of unique recommendations per product\n",
    "        if len(product_recommendations) > 0:\n",
    "            diversity = sum(len(recommendations) for recommendations in product_recommendations.values()) / len(product_recommendations)\n",
    "        else:\n",
    "            diversity = 0\n",
    "        \n",
    "        return diversity\n",
    "    \n",
    "    def analyze_category_relationships(self):\n",
    "        \"\"\"\n",
    "        Analyze the Cross-Category Complementarity.\n",
    "        \n",
    "        Returns:\n",
    "            dict: Analysis results for both methods\n",
    "        \"\"\"\n",
    "        results = {'apriori': {}, 'word2vec': {}}\n",
    "        \n",
    "        # Only proceed if both methods have been run and category information is available\n",
    "        if self.product_to_category and self.apriori_product_pairs is not None and self.word2vec_complementary is not None:\n",
    "            # Analyze Apriori category relationships\n",
    "            if 'Original Product category' in self.apriori_product_pairs.columns:\n",
    "                # Count frequency of category combinations\n",
    "                category_combinations = self.apriori_product_pairs.groupby(\n",
    "                    ['Original Product category', 'Complementary Product category']\n",
    "                ).size().reset_index(name='frequency')\n",
    "                \n",
    "                # Sort by frequency\n",
    "                category_combinations = category_combinations.sort_values('frequency', ascending=False)\n",
    "                \n",
    "                # Calculate percentage of cross-category vs. same-category recommendations\n",
    "                same_category = self.apriori_product_pairs[\n",
    "                    self.apriori_product_pairs['Original Product category'] == \n",
    "                    self.apriori_product_pairs['Complementary Product category']\n",
    "                ]\n",
    "                same_category_percentage = len(same_category) / len(self.apriori_product_pairs) * 100\n",
    "                \n",
    "                results['apriori'] = {\n",
    "                    'top_category_combinations': category_combinations.head(10),\n",
    "                    'same_category_percentage': same_category_percentage,\n",
    "                    'cross_category_percentage': 100 - same_category_percentage\n",
    "                }\n",
    "            \n",
    "            # Analyze Word2Vec category relationships\n",
    "            if 'Original Product category' in self.word2vec_complementary.columns:\n",
    "                # Count frequency of category combinations\n",
    "                category_combinations = self.word2vec_complementary.groupby(\n",
    "                    ['Original Product category', 'Complementary Product category']\n",
    "                ).size().reset_index(name='frequency')\n",
    "                \n",
    "                # Sort by frequency\n",
    "                category_combinations = category_combinations.sort_values('frequency', ascending=False)\n",
    "                \n",
    "                # Calculate percentage of cross-category vs. same-category recommendations\n",
    "                same_category = self.word2vec_complementary[\n",
    "                    self.word2vec_complementary['Original Product category'] == \n",
    "                    self.word2vec_complementary['Complementary Product category']\n",
    "                ]\n",
    "                same_category_percentage = len(same_category) / len(self.word2vec_complementary) * 100\n",
    "                \n",
    "                results['word2vec'] = {\n",
    "                    'top_category_combinations': category_combinations.head(10),\n",
    "                    'same_category_percentage': same_category_percentage,\n",
    "                    'cross_category_percentage': 100 - same_category_percentage\n",
    "                }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def compare_models(self):\n",
    "        \"\"\"\n",
    "        Compare performance metrics between Apriori and Word2Vec.\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame: Comparison of metrics\n",
    "        \"\"\"\n",
    "        # Ensure both models have been run\n",
    "        if not self.metrics['apriori'] or not self.metrics['word2vec']:\n",
    "            print(\"Both models need to be run before comparison\")\n",
    "            return\n",
    "        \n",
    "        # Create comparison DataFrame\n",
    "        comparison = pd.DataFrame({\n",
    "            'Metric': [\n",
    "                'Execution Time (s)',\n",
    "                'Memory Usage (MB)',\n",
    "                'Number of Rules/Recommendations',\n",
    "                'Coverage',\n",
    "                'Diversity'\n",
    "            ],\n",
    "            'Apriori': [\n",
    "                self.metrics['apriori']['execution_time'],\n",
    "                self.metrics['apriori']['memory_usage'],\n",
    "                self.metrics['apriori']['num_rules'],\n",
    "                self.metrics['apriori']['coverage'],\n",
    "                self.metrics['apriori']['diversity']\n",
    "            ],\n",
    "            'Word2Vec': [\n",
    "                self.metrics['word2vec']['execution_time'],\n",
    "                self.metrics['word2vec']['memory_usage'],\n",
    "                self.metrics['word2vec']['num_recommendations'],\n",
    "                self.metrics['word2vec']['coverage'],\n",
    "                self.metrics['word2vec']['diversity']\n",
    "            ]\n",
    "        })\n",
    "        \n",
    "        return comparison\n",
    "    \n",
    "    def visualize_comparison(self, save_path=None):\n",
    "        \"\"\"\n",
    "        Visualize comparison metrics between Apriori and Word2Vec.\n",
    "        \n",
    "        Args:\n",
    "            save_path (str, optional): Path to save the visualization\n",
    "        \"\"\"\n",
    "        comparison = self.compare_models()\n",
    "        \n",
    "        # Prepare data for plotting\n",
    "        metrics_to_plot = ['Execution Time (s)', 'Memory Usage (MB)', 'Coverage', 'Diversity']\n",
    "        \n",
    "        # Set up the figure\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, metric in enumerate(metrics_to_plot):\n",
    "            data = comparison[comparison['Metric'] == metric]\n",
    "            values = data.iloc[0, 1:].astype(float)\n",
    "            \n",
    "            # Create bar plot\n",
    "            ax = axes[i]\n",
    "            sns.barplot(x=['Apriori', 'Word2Vec'], y=values, ax=ax, palette='viridis')\n",
    "            ax.set_title(f\"{self.subset_name} - {metric}\", fontsize=14)\n",
    "            ax.set_ylabel('Value', fontsize=12)\n",
    "            ax.set_xlabel('')\n",
    "            \n",
    "            # Add values on top of bars\n",
    "            for j, v in enumerate(values):\n",
    "                ax.text(j, v, f'{v:.4f}', ha='center', va='bottom', fontsize=12)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    def visualize_category_relationships(self, save_path=None):\n",
    "        \"\"\"\n",
    "        Visualize category relationships for both methods.\n",
    "        \n",
    "        Args:\n",
    "            save_path (str, optional): Path to save the visualization\n",
    "        \"\"\"\n",
    "        # Only proceed if category analysis has been performed\n",
    "        category_analysis = self.analyze_category_relationships()\n",
    "        \n",
    "        if not category_analysis['apriori'] or not category_analysis['word2vec']:\n",
    "            print(\"Category analysis is not available. Make sure models have been run and category information exists.\")\n",
    "            return\n",
    "        \n",
    "        # Set up the figure\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "        \n",
    "        # Plot for Apriori\n",
    "        axes[0].bar(['Same category', 'Cross category'], \n",
    "                 [category_analysis['apriori']['same_category_percentage'], \n",
    "                  category_analysis['apriori']['cross_category_percentage']])\n",
    "        axes[0].set_title(f'{self.subset_name} - Apriori: Category Relationships', fontsize=14)\n",
    "        axes[0].set_ylabel('Percentage (%)', fontsize=12)\n",
    "        \n",
    "        # Add values on top of bars\n",
    "        for i, v in enumerate([category_analysis['apriori']['same_category_percentage'], \n",
    "                               category_analysis['apriori']['cross_category_percentage']]):\n",
    "            axes[0].text(i, v, f'{v:.1f}%', ha='center', va='bottom', fontsize=12)\n",
    "        \n",
    "        # Plot for Word2Vec\n",
    "        axes[1].bar(['Same category', 'Cross category'], \n",
    "                 [category_analysis['word2vec']['same_category_percentage'], \n",
    "                  category_analysis['word2vec']['cross_category_percentage']])\n",
    "        axes[1].set_title(f'{self.subset_name} - Word2Vec: Category Relationships', fontsize=14)\n",
    "        axes[1].set_ylabel('Percentage (%)', fontsize=12)\n",
    "        \n",
    "        # Add values on top of bars\n",
    "        for i, v in enumerate([category_analysis['word2vec']['same_category_percentage'], \n",
    "                               category_analysis['word2vec']['cross_category_percentage']]):\n",
    "            axes[1].text(i, v, f'{v:.1f}%', ha='center', va='bottom', fontsize=12)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    def save_results(self, output_dir=None):\n",
    "        \"\"\"\n",
    "        Save evaluation results to files.\n",
    "        \n",
    "        Args:\n",
    "            output_dir (str, optional): Directory to save results\n",
    "        \"\"\"\n",
    "        if output_dir is None:\n",
    "            output_dir = self.path_results\n",
    "            \n",
    "        # Create a subdirectory for this subset\n",
    "        subset_dir = os.path.join(output_dir, self.subset_name)\n",
    "        os.makedirs(subset_dir, exist_ok=True)\n",
    "        \n",
    "        # Save comparison metrics\n",
    "        comparison = self.compare_models()\n",
    "        comparison.to_csv(os.path.join(subset_dir, f'{self.subset_name}_model_comparison_metrics.csv'), index=False)\n",
    "        \n",
    "        # Save Apriori rules if available\n",
    "        if self.apriori_rules is not None:\n",
    "            self.apriori_rules.to_excel(os.path.join(subset_dir, f'{self.subset_name}_apriori_rules.xlsx'), index=False)\n",
    "            \n",
    "        # Save Apriori product pairs with categories if available\n",
    "        if hasattr(self, 'apriori_product_pairs') and self.apriori_product_pairs is not None:\n",
    "            self.apriori_product_pairs.to_excel(os.path.join(subset_dir, f'{self.subset_name}_apriori_product_pairs_with_categories.xlsx'), index=False)\n",
    "        \n",
    "        # Save Word2Vec recommendations if available\n",
    "        if self.word2vec_complementary is not None:\n",
    "            self.word2vec_complementary.to_excel(os.path.join(subset_dir, f'{self.subset_name}_word2vec_recommendations.xlsx'), index=False)\n",
    "        \n",
    "        # Save visualization\n",
    "        self.visualize_comparison(save_path=os.path.join(subset_dir, f'{self.subset_name}_metric_comparison.png'))\n",
    "        \n",
    "        # Save category relationship visualization if applicable\n",
    "        if hasattr(self, 'product_to_category') and self.product_to_category:\n",
    "            self.visualize_category_relationships(save_path=os.path.join(subset_dir, f'{self.subset_name}_category_relationships.png'))\n",
    "            \n",
    "            # Save category analysis results\n",
    "            category_analysis = self.analyze_category_relationships()\n",
    "            \n",
    "            # Save top category combinations for Apriori\n",
    "            if 'top_category_combinations' in category_analysis['apriori']:\n",
    "                category_analysis['apriori']['top_category_combinations'].to_excel(\n",
    "                    os.path.join(subset_dir, f'{self.subset_name}_apriori_top_category_combinations.xlsx'), index=False\n",
    "                )\n",
    "            \n",
    "            # Save top category combinations for Word2Vec\n",
    "            if 'top_category_combinations' in category_analysis['word2vec']:\n",
    "                category_analysis['word2vec']['top_category_combinations'].to_excel(\n",
    "                    os.path.join(subset_dir, f'{self.subset_name}_word2vec_top_category_combinations.xlsx'), index=False\n",
    "                )\n",
    "        \n",
    "        print(f\"Results for {self.subset_name} saved to {subset_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_excel(os.path.join(path, excel_file))\n",
    "    \n",
    "# ===== DATA PARTITIONING =====\n",
    "# Split dataset into whole, first third, and last two thirds.\n",
    "n = len(full_data)\n",
    "one_third_index = n // 3\n",
    "\n",
    "df_whole = full_data.copy()\n",
    "df_first_third = full_data.iloc[:one_third_index]\n",
    "df_last_two_thirds = full_data.iloc[one_third_index:]\n",
    "\n",
    "print(f\"Full dataset: {len(df_whole)} records\")\n",
    "print(f\"First third: {len(df_first_third)} records\")\n",
    "print(f\"Last two thirds: {len(df_last_two_thirds)} records\")\n",
    "\n",
    "# Create results directory\n",
    "os.makedirs(path_results, exist_ok=True)\n",
    "\n",
    "# ===== EVALUATE WHOLE DATASET ====="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Algorithms on Data-Portions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===== EVALUATING WHOLE DATASET =====\")\n",
    "evaluator_whole = ModelEvaluator(path, path_results, excel_file, df_whole, \"whole_dataset\")\n",
    "evaluator_whole.run_apriori()\n",
    "evaluator_whole.run_word2vec()\n",
    "evaluator_whole.save_results()\n",
    "\n",
    "# ===== EVALUATE FIRST THIRD =====\n",
    "print(\"\\n===== EVALUATING FIRST THIRD OF DATASET =====\")\n",
    "evaluator_first_third = ModelEvaluator(path, path_results, excel_file, df_first_third, \"first_third\")\n",
    "evaluator_first_third.run_apriori()\n",
    "evaluator_first_third.run_word2vec()\n",
    "evaluator_first_third.save_results()\n",
    "\n",
    "# ===== EVALUATE LAST TWO THIRDS =====\n",
    "print(\"\\n===== EVALUATING LAST TWO THIRDS OF DATASET =====\")\n",
    "evaluator_last_two_thirds = ModelEvaluator(path, path_results, excel_file, df_last_two_thirds, \"last_two_thirds\")\n",
    "evaluator_last_two_thirds.run_apriori()\n",
    "evaluator_last_two_thirds.run_word2vec()\n",
    "evaluator_last_two_thirds.save_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== COMBINED VISUALIZATION =====\n",
    "# Compare key metrics across all three datasets\n",
    "def create_combined_comparison():\n",
    "    metrics = ['execution_time', 'memory_usage', 'coverage', 'diversity']\n",
    "    datasets = ['whole_dataset', 'first_third', 'last_two_thirds']\n",
    "    \n",
    "    for metric in metrics:\n",
    "        # Set up figure\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "        # Prepare data\n",
    "        apriori_values = [\n",
    "            evaluator_whole.metrics['apriori'][metric],\n",
    "            evaluator_first_third.metrics['apriori'][metric],\n",
    "            evaluator_last_two_thirds.metrics['apriori'][metric]\n",
    "        ]\n",
    "        \n",
    "        word2vec_values = [\n",
    "            evaluator_whole.metrics['word2vec'][metric],\n",
    "            evaluator_first_third.metrics['word2vec'][metric],\n",
    "            evaluator_last_two_thirds.metrics['word2vec'][metric]\n",
    "        ]\n",
    "        \n",
    "        # Set bar positions\n",
    "        bar_width = 0.35\n",
    "        index = np.arange(len(datasets))\n",
    "        \n",
    "        # Create bars\n",
    "        bar1 = ax.bar(index, apriori_values, bar_width, label='Apriori')\n",
    "        bar2 = ax.bar(index + bar_width, word2vec_values, bar_width, label='Word2Vec')\n",
    "        \n",
    "        # Add labels and title\n",
    "        ax.set_xlabel('Dataset')\n",
    "        ax.set_ylabel(f'{metric.replace(\"_\", \" \").title()}')\n",
    "        ax.set_title(f'Comparison of {metric.replace(\"_\", \" \").title()} Across Datasets')\n",
    "        ax.set_xticks(index + bar_width / 2)\n",
    "        ax.set_xticklabels([d.replace(\"_\", \" \").title() for d in datasets])\n",
    "        ax.legend()\n",
    "        \n",
    "        # Add values on top of bars\n",
    "        for i, v in enumerate(apriori_values):\n",
    "            ax.text(i - 0.05, v + (max(apriori_values + word2vec_values) * 0.02), \n",
    "                    f'{v:.2f}', ha='center', fontsize=9)\n",
    "                    \n",
    "        for i, v in enumerate(word2vec_values):\n",
    "            ax.text(i + bar_width - 0.05, v + (max(apriori_values + word2vec_values) * 0.02), \n",
    "                    f'{v:.2f}', ha='center', fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(path_results, f'combined_{metric}_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "    # Also create a table with all metrics\n",
    "    combined_metrics = pd.DataFrame({\n",
    "        'Metric': ['Execution Time (s)', 'Memory Usage (MB)', 'Coverage', 'Diversity'],\n",
    "        'Whole_Apriori': [evaluator_whole.metrics['apriori']['execution_time'], \n",
    "                        evaluator_whole.metrics['apriori']['memory_usage'], \n",
    "                        evaluator_whole.metrics['apriori']['coverage'], \n",
    "                        evaluator_whole.metrics['apriori']['diversity']],\n",
    "        'Whole_Word2Vec': [evaluator_whole.metrics['word2vec']['execution_time'], \n",
    "                            evaluator_whole.metrics['word2vec']['memory_usage'], \n",
    "                            evaluator_whole.metrics['word2vec']['coverage'], \n",
    "                            evaluator_whole.metrics['word2vec']['diversity']],\n",
    "                            'First_Third_Apriori': [evaluator_first_third.metrics['apriori']['execution_time'], \n",
    "                                evaluator_first_third.metrics['apriori']['memory_usage'], \n",
    "                                evaluator_first_third.metrics['apriori']['coverage'], \n",
    "                                evaluator_first_third.metrics['apriori']['diversity']],\n",
    "        'First_Third_Word2Vec': [evaluator_first_third.metrics['word2vec']['execution_time'], \n",
    "                                evaluator_first_third.metrics['word2vec']['memory_usage'], \n",
    "                                evaluator_first_third.metrics['word2vec']['coverage'], \n",
    "                                evaluator_first_third.metrics['word2vec']['diversity']],\n",
    "        'Last_Two_Thirds_Apriori': [evaluator_last_two_thirds.metrics['apriori']['execution_time'], \n",
    "                                    evaluator_last_two_thirds.metrics['apriori']['memory_usage'], \n",
    "                                    evaluator_last_two_thirds.metrics['apriori']['coverage'], \n",
    "                                    evaluator_last_two_thirds.metrics['apriori']['diversity']],\n",
    "        'Last_Two_Thirds_Word2Vec': [evaluator_last_two_thirds.metrics['word2vec']['execution_time'], \n",
    "                                    evaluator_last_two_thirds.metrics['word2vec']['memory_usage'], \n",
    "                                    evaluator_last_two_thirds.metrics['word2vec']['coverage'], \n",
    "                                    evaluator_last_two_thirds.metrics['word2vec']['diversity']]\n",
    "    })\n",
    "    \n",
    "    # Save combined metrics\n",
    "    combined_metrics.to_csv(os.path.join(path_results, 'combined_metrics_comparison.csv'), index=False)\n",
    "    \n",
    "    # Create a readable HTML table for better visualization\n",
    "    html_table = combined_metrics.to_html(index=False)\n",
    "    with open(os.path.join(path_results, 'combined_metrics_comparison.html'), 'w') as f:\n",
    "        f.write(\"\"\"\n",
    "        <html>\n",
    "        <head>\n",
    "            <style>\n",
    "                table { border-collapse: collapse; width: 100%; }\n",
    "                th, td { text-align: center; padding: 8px; border: 1px solid #ddd; }\n",
    "                th { background-color: #f2f2f2; }\n",
    "                tr:nth-child(even) { background-color: #f9f9f9; }\n",
    "            </style>\n",
    "        </head>\n",
    "        <body>\n",
    "        <h2>Combined Metrics Comparison</h2>\n",
    "        \"\"\")\n",
    "        f.write(html_table)\n",
    "        f.write(\"</body></html>\")\n",
    "    \n",
    "    print(\"Combined comparison visualizations and metrics saved.\")\n",
    "\n",
    "# Import numpy for the bar positions\n",
    "import numpy as np\n",
    "\n",
    "# Create combined comparison\n",
    "create_combined_comparison()\n",
    "\n",
    "print(\"\\nAll evaluations completed and results saved.\")\n",
    "\n",
    "\n",
    "\n",
    "def create_combined_category_comparison():\n",
    "    \"\"\"\n",
    "    Create visualizations and tables comparing cross-category relationships across all data partitions.\n",
    "    \"\"\"\n",
    "    datasets = ['whole_dataset', 'first_third', 'last_two_thirds']\n",
    "    models = ['apriori', 'word2vec']\n",
    "    \n",
    "    # Collect category analysis results from all evaluators\n",
    "    whole_analysis = evaluator_whole.analyze_category_relationships()\n",
    "    first_third_analysis = evaluator_first_third.analyze_category_relationships()\n",
    "    last_two_thirds_analysis = evaluator_last_two_thirds.analyze_category_relationships()\n",
    "    \n",
    "    # Create side-by-side comparison of same vs cross-category percentages\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Extract same-category and cross-category percentages\n",
    "        same_category_values = [\n",
    "            whole_analysis[model]['same_category_percentage'],\n",
    "            first_third_analysis[model]['same_category_percentage'],\n",
    "            last_two_thirds_analysis[model]['same_category_percentage']\n",
    "        ]\n",
    "        \n",
    "        cross_category_values = [\n",
    "            whole_analysis[model]['cross_category_percentage'],\n",
    "            first_third_analysis[model]['cross_category_percentage'],\n",
    "            last_two_thirds_analysis[model]['cross_category_percentage']\n",
    "        ]\n",
    "        \n",
    "        # Set bar positions\n",
    "        bar_width = 0.35\n",
    "        index = np.arange(len(datasets))\n",
    "        \n",
    "        # Create bars\n",
    "        bar1 = ax.bar(index, same_category_values, bar_width, label='Same Category')\n",
    "        bar2 = ax.bar(index + bar_width, cross_category_values, bar_width, label='Cross Category')\n",
    "        \n",
    "        # Add labels and title\n",
    "        ax.set_xlabel('Dataset')\n",
    "        ax.set_ylabel('Percentage (%)')\n",
    "        ax.set_title(f'{model.capitalize()} Model: Category Relationships Across Datasets')\n",
    "        ax.set_xticks(index + bar_width / 2)\n",
    "        ax.set_xticklabels([d.replace(\"_\", \" \").title() for d in datasets])\n",
    "        ax.legend()\n",
    "        \n",
    "        # Add values on top of bars\n",
    "        for j, v in enumerate(same_category_values):\n",
    "            ax.text(j - 0.05, v + 2, f'{v:.1f}%', ha='center', fontsize=9)\n",
    "                    \n",
    "        for j, v in enumerate(cross_category_values):\n",
    "            ax.text(j + bar_width - 0.05, v + 2, f'{v:.1f}%', ha='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(path_results, 'combined_category_relationships.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Create a table with all category metrics\n",
    "    combined_category_metrics = pd.DataFrame({\n",
    "        'Metric': ['Same Category %', 'Cross Category %'],\n",
    "        'Whole_Apriori': [\n",
    "            whole_analysis['apriori']['same_category_percentage'],\n",
    "            whole_analysis['apriori']['cross_category_percentage']\n",
    "        ],\n",
    "        'Whole_Word2Vec': [\n",
    "            whole_analysis['word2vec']['same_category_percentage'],\n",
    "            whole_analysis['word2vec']['cross_category_percentage']\n",
    "        ],\n",
    "        'First_Third_Apriori': [\n",
    "            first_third_analysis['apriori']['same_category_percentage'],\n",
    "            first_third_analysis['apriori']['cross_category_percentage']\n",
    "        ],\n",
    "        'First_Third_Word2Vec': [\n",
    "            first_third_analysis['word2vec']['same_category_percentage'],\n",
    "            first_third_analysis['word2vec']['cross_category_percentage']\n",
    "        ],\n",
    "        'Last_Two_Thirds_Apriori': [\n",
    "            last_two_thirds_analysis['apriori']['same_category_percentage'],\n",
    "            last_two_thirds_analysis['apriori']['cross_category_percentage']\n",
    "        ],\n",
    "        'Last_Two_Thirds_Word2Vec': [\n",
    "            last_two_thirds_analysis['word2vec']['same_category_percentage'],\n",
    "            last_two_thirds_analysis['word2vec']['cross_category_percentage']\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Save combined category metrics\n",
    "    combined_category_metrics.to_csv(os.path.join(path_results, 'combined_category_metrics.csv'), index=False)\n",
    "    \n",
    "    # Create a readable HTML table for better visualization\n",
    "    html_table = combined_category_metrics.to_html(index=False)\n",
    "    with open(os.path.join(path_results, 'combined_category_metrics.html'), 'w') as f:\n",
    "        f.write(\"\"\"\n",
    "        <html>\n",
    "        <head>\n",
    "            <style>\n",
    "                table { border-collapse: collapse; width: 100%; }\n",
    "                th, td { text-align: center; padding: 8px; border: 1px solid #ddd; }\n",
    "                th { background-color: #f2f2f2; }\n",
    "                tr:nth-child(even) { background-color: #f9f9f9; }\n",
    "            </style>\n",
    "        </head>\n",
    "        <body>\n",
    "        <h2>Combined Category Relationships Comparison</h2>\n",
    "        \"\"\")\n",
    "        f.write(html_table)\n",
    "        f.write(\"</body></html>\")\n",
    "    \n",
    "    # Create a comparison of top category pairs across datasets\n",
    "    compare_top_category_pairs(whole_analysis, first_third_analysis, last_two_thirds_analysis)\n",
    "    \n",
    "    print(\"Combined category relationship comparisons and metrics saved.\")\n",
    "\n",
    "def compare_top_category_pairs(whole_analysis, first_third_analysis, last_two_thirds_analysis):\n",
    "    \"\"\"\n",
    "    Compare top category pairs across different datasets.\n",
    "    \"\"\"\n",
    "    models = ['apriori', 'word2vec']\n",
    "    datasets = ['Whole Dataset', 'First Third', 'Last Two Thirds']\n",
    "    analyses = [whole_analysis, first_third_analysis, last_two_thirds_analysis]\n",
    "    \n",
    "    for model in models:\n",
    "        # Create figure for this model\n",
    "        plt.figure(figsize=(15, 12))\n",
    "        \n",
    "        # Get top 5 category pairs from each dataset for this model\n",
    "        all_top_pairs = []\n",
    "        \n",
    "        for i, analysis in enumerate(analyses):\n",
    "            if 'top_category_combinations' in analysis[model]:\n",
    "                top_pairs = analysis[model]['top_category_combinations'].head(5)\n",
    "                \n",
    "                # Format category pairs for consistent comparison\n",
    "                for _, row in top_pairs.iterrows():\n",
    "                    pair_name = f\"{row['Original Product category']} â†’ {row['Complementary Product category']}\"\n",
    "                    all_top_pairs.append((pair_name, row['frequency'], datasets[i]))\n",
    "        \n",
    "        # Get unique category pairs across all datasets\n",
    "        unique_pairs = list(set([pair[0] for pair in all_top_pairs]))\n",
    "        \n",
    "        # Create a dictionary to hold frequencies for each dataset\n",
    "        pair_frequencies = {dataset: {pair: 0 for pair in unique_pairs} for dataset in datasets}\n",
    "        \n",
    "        # Fill in the frequencies\n",
    "        for pair_name, freq, dataset in all_top_pairs:\n",
    "            pair_frequencies[dataset][pair_name] = freq\n",
    "        \n",
    "        # Convert to DataFrame for plotting\n",
    "        df_pairs = pd.DataFrame(pair_frequencies)\n",
    "        \n",
    "        # Sort by total frequency across datasets\n",
    "        df_pairs['Total'] = df_pairs.sum(axis=1)\n",
    "        df_pairs = df_pairs.sort_values('Total', ascending=False).head(10)\n",
    "        df_pairs = df_pairs.drop('Total', axis=1)\n",
    "        \n",
    "        # Create grouped bar chart\n",
    "        ax = df_pairs.plot(kind='bar', figsize=(15, 8))\n",
    "        \n",
    "        plt.title(f'Top Category Pairs Comparison - {model.capitalize()} Model', fontsize=16)\n",
    "        plt.xlabel('Category Pair', fontsize=14)\n",
    "        plt.ylabel('Frequency', fontsize=14)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the figure\n",
    "        plt.savefig(os.path.join(path_results, f'{model}_top_category_pairs_comparison.png'), \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Also save as CSV\n",
    "        df_pairs.to_csv(os.path.join(path_results, f'{model}_top_category_pairs_comparison.csv'))\n",
    "\n",
    "# Add this to the end of your notebook\n",
    "import numpy as np\n",
    "\n",
    "# Create combined category comparison\n",
    "create_combined_category_comparison()\n",
    "\n",
    "print(\"\\nAll category relationship comparisons completed and results saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
