{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis\n",
    "\n",
    "- **How many rows**: Number of roows in the dataset.\n",
    "- **How many columns**: Number of columns in the dataset.\n",
    "- **List of the columns**: List of columns in the dataset.\n",
    "- **Total Products**: Number of products in the dataset.\n",
    "- **Distinct Products**: Number of unique products.\n",
    "- **Total Transactions**: Number of transactions recorded.\n",
    "- **Total Customers**: Number of customers in the dataset.\n",
    "- **Distinct Categories**: Number of unique product categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== DATASET OVERVIEW =====\n",
      "How many rows: 520609\n",
      "How many columns: 8\n",
      "List of columns: ['BillNo', 'Itemname', 'Quantity', 'Date', 'Price', 'CustomerID', 'Country', 'category']\n",
      "Total Products: 520609\n",
      "Distinct Products: 4185\n",
      "Total Transactions: 20208\n",
      "Total Customers: 4297\n",
      "Distinct Categories: 21\n",
      "\n",
      "===== CATEGORY DISTRIBUTION =====\n",
      "Kitchen & Dining: 105749 products (20.31%)\n",
      "Home Decor: 97277 products (18.69%)\n",
      "Stationery & Office: 47941 products (9.21%)\n",
      "Seasonal & Holidays: 40666 products (7.81%)\n",
      "Kids & Toys: 40642 products (7.81%)\n",
      "Textiles & Cozy Items: 25770 products (4.95%)\n",
      "Vintage & Collectibles: 24355 products (4.68%)\n",
      "Fashion & Accessories: 24224 products (4.65%)\n",
      "Party Supplies: 23609 products (4.53%)\n",
      "Storage & Organization: 22690 products (4.36%)\n",
      "Garden & Outdoor: 18558 products (3.56%)\n",
      "Crafts & DIY: 17090 products (3.28%)\n",
      "Lighting: 7022 products (1.35%)\n",
      "Games & Puzzles: 7013 products (1.35%)\n",
      "Electronics & Gadgets: 5269 products (1.01%)\n",
      "Bath & Body: 5024 products (0.97%)\n",
      "Gifts & Special Occasion: 3005 products (0.58%)\n",
      "Pets & Animals: 2012 products (0.39%)\n",
      "no_list: 963 products (0.18%)\n",
      "Books & Magazines: 851 products (0.16%)\n",
      "Miscellaneous: 754 products (0.14%)\n",
      "\n",
      "Date Range: 2010-12-01 08:26:00 to 2011-12-09 12:50:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path = r'C:\\Users\\moham\\Apriori_VS_Word2Vec'\n",
    "excel_file = 'df_merged_items_category.xlsx'\n",
    "excel_file_path = os.path.join(path, excel_file)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel(excel_file_path)\n",
    "\n",
    "# Basic Dataset Statistics\n",
    "print(\"===== DATASET OVERVIEW =====\")\n",
    "print(f\"How many rows: {df.shape[0]}\")\n",
    "print(f\"How many columns: {df.shape[1]}\")\n",
    "print(f\"List of columns: {list(df.columns)}\")\n",
    "\n",
    "# Total and distinct products\n",
    "total_products = df.shape[0]\n",
    "distinct_products = df['Itemname'].nunique()\n",
    "print(f\"Total Products: {total_products}\")\n",
    "print(f\"Distinct Products: {distinct_products}\")\n",
    "\n",
    "# Transactions analysis\n",
    "total_transactions = df['BillNo'].nunique()\n",
    "print(f\"Total Transactions: {total_transactions}\")\n",
    "\n",
    "# Customer analysis\n",
    "total_customers = df['CustomerID'].nunique()\n",
    "print(f\"Total Customers: {total_customers}\")\n",
    "\n",
    "# Category analysis\n",
    "if 'category' in df.columns:\n",
    "    distinct_categories = df['category'].nunique()\n",
    "    print(f\"Distinct Categories: {distinct_categories}\")\n",
    "    # Category distribution\n",
    "    category_counts = df['category'].value_counts()\n",
    "    print(\"\\n===== CATEGORY DISTRIBUTION =====\")\n",
    "    for category, count in category_counts.items():\n",
    "        percentage = (count / total_products) * 100\n",
    "        print(f\"{category}: {count} products ({percentage:.2f}%)\")\n",
    "\n",
    "# Date range\n",
    "if 'Date' in df.columns:\n",
    "    min_date = df['Date'].min()\n",
    "    max_date = df['Date'].max()\n",
    "    print(f\"\\nDate Range: {min_date} to {max_date}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transaction Patterns\n",
    "\n",
    "Analyze the purchasing patterns visible in the data:\n",
    "\n",
    "- **Transaction frequency over time**: Daily, weekly, and monthly patterns.\n",
    "- **Average items per transaction**.\n",
    "- **Distribution of transaction sizes**: Histogram showing the number of items per invoice.\n",
    "- **Temporal patterns**: Time of day, day of week, and seasonal trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== TRANSACTION PATTERNS =====\n",
      "\n",
      "1. Transaction Frequency Over Time\n",
      "\n",
      "Daily Transaction Counts:\n",
      "Date_Only\n",
      "2010-12-01    125\n",
      "2010-12-02    141\n",
      "2010-12-03     68\n",
      "2010-12-05     88\n",
      "2010-12-06    102\n",
      "             ... \n",
      "2011-12-05    129\n",
      "2011-12-06    117\n",
      "2011-12-07    117\n",
      "2011-12-08    122\n",
      "2011-12-09     44\n",
      "Name: BillNo, Length: 305, dtype: int64\n",
      "\n",
      "Transactions by Day of Week:\n",
      "Day\n",
      "Monday       3159.0\n",
      "Tuesday      3615.0\n",
      "Wednesday    3751.0\n",
      "Thursday     4292.0\n",
      "Friday       3209.0\n",
      "Saturday        NaN\n",
      "Sunday       2182.0\n",
      "Name: BillNo, dtype: float64\n",
      "\n",
      "Transactions by Hour of Day:\n",
      "Hour\n",
      "6        1\n",
      "7       26\n",
      "8      534\n",
      "9     1485\n",
      "10    2352\n",
      "11    2445\n",
      "12    3240\n",
      "13    2774\n",
      "14    2472\n",
      "15    2394\n",
      "16    1386\n",
      "17     714\n",
      "18     227\n",
      "19     141\n",
      "20      18\n",
      "Name: BillNo, dtype: int64\n",
      "\n",
      "2. Average Items per Transaction\n",
      "Average Items per Transaction: 25.76\n",
      "Median Items per Transaction: 15.0\n",
      "Min Items per Transaction: 1\n",
      "Max Items per Transaction: 1114\n",
      "\n",
      "3. Distribution of Transaction Sizes\n",
      "\n",
      "Transaction Size Percentiles:\n",
      "25th percentile: 5.0 items\n",
      "50th percentile (median): 15.0 items\n",
      "75th percentile: 28.0 items\n",
      "90th percentile: 53.0 items\n",
      "95th percentile: 77.0 items\n",
      "99th percentile: 218.0 items\n",
      "\n",
      "Transaction Size Distribution:\n",
      "1-4 items: 2838 transactions (14.04%)\n",
      "5-9 items: 2922 transactions (14.46%)\n",
      "10-14 items: 2562 transactions (12.68%)\n",
      "15-19 items: 2305 transactions (11.41%)\n",
      "20-29 items: 2795 transactions (13.83%)\n",
      "30-49 items: 2367 transactions (11.71%)\n",
      "50-99 items: 1533 transactions (7.59%)\n",
      "100+ items: 662 transactions (3.28%)\n",
      "\n",
      "4. Temporal Patterns - Day of Week vs Hour\n",
      "\n",
      "Busiest Hour for Each Day:\n",
      "Monday: 12.0:00\n",
      "Tuesday: 12.0:00\n",
      "Wednesday: 12.0:00\n",
      "Thursday: 12.0:00\n",
      "Friday: 12.0:00\n",
      "Saturday: nan:00\n",
      "Sunday: 12.0:00\n",
      "\n",
      "Visualizations saved to C:\\Users\\moham\\Apriori_VS_Word2Vec\\analysis_plots\n",
      "\n",
      "Transaction pattern analysis complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\AppData\\Local\\Temp\\ipykernel_29388\\3219655145.py:161: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  busiest_hours = day_hour_counts.idxmax(axis=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Path setup\n",
    "path = r'C:\\Users\\moham\\Apriori_VS_Word2Vec'\n",
    "excel_file = 'df_merged_items_category.xlsx'\n",
    "excel_file_path = os.path.join(path, excel_file)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel(excel_file_path)\n",
    "\n",
    "# Ensure Date is in datetime format\n",
    "if 'Date' in df.columns:\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['Date']):\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Create plot directory\n",
    "plots_dir = os.path.join(path, 'analysis_plots')\n",
    "if not os.path.exists(plots_dir):\n",
    "    os.makedirs(plots_dir)\n",
    "\n",
    "# ===== TRANSACTION PATTERNS ANALYSIS =====\n",
    "print(\"\\n===== TRANSACTION PATTERNS =====\")\n",
    "\n",
    "# 1. Transaction frequency over time\n",
    "print(\"\\n1. Transaction Frequency Over Time\")\n",
    "\n",
    "# Add date components\n",
    "df['Date_Only'] = df['Date'].dt.date\n",
    "df['Day'] = df['Date'].dt.day_name()\n",
    "df['Hour'] = df['Date'].dt.hour\n",
    "df['Month'] = df['Date'].dt.month_name()\n",
    "df['Week'] = df['Date'].dt.isocalendar().week\n",
    "\n",
    "# Daily transaction counts\n",
    "daily_transactions = df.groupby('Date_Only')['BillNo'].nunique()\n",
    "print(\"\\nDaily Transaction Counts:\")\n",
    "print(daily_transactions)\n",
    "\n",
    "# Plot daily transactions\n",
    "plt.figure(figsize=(12, 6))\n",
    "daily_transactions.plot()\n",
    "plt.title('Number of Transactions by Day')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Transactions')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, 'daily_transactions.png'))\n",
    "plt.close()\n",
    "\n",
    "# Day of week analysis\n",
    "day_of_week_transactions = df.groupby('Day')['BillNo'].nunique().reindex(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    "print(\"\\nTransactions by Day of Week:\")\n",
    "print(day_of_week_transactions)\n",
    "\n",
    "# Plot day of week transactions\n",
    "plt.figure(figsize=(10, 6))\n",
    "day_of_week_transactions.plot(kind='bar')\n",
    "plt.title('Number of Transactions by Day of Week')\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Number of Transactions')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, 'day_of_week_transactions.png'))\n",
    "plt.close()\n",
    "\n",
    "# Hourly pattern\n",
    "hourly_transactions = df.groupby('Hour')['BillNo'].nunique()\n",
    "print(\"\\nTransactions by Hour of Day:\")\n",
    "print(hourly_transactions)\n",
    "\n",
    "# Plot hourly transactions\n",
    "plt.figure(figsize=(12, 6))\n",
    "hourly_transactions.plot(kind='bar')\n",
    "plt.title('Number of Transactions by Hour of Day')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Number of Transactions')\n",
    "plt.xticks(range(24), [f'{i}:00' for i in range(24)])\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, 'hourly_transactions.png'))\n",
    "plt.close()\n",
    "\n",
    "# 2. Average items per transaction\n",
    "print(\"\\n2. Average Items per Transaction\")\n",
    "# Count items per transaction\n",
    "items_per_transaction = df.groupby('BillNo').size()\n",
    "avg_items = items_per_transaction.mean()\n",
    "median_items = items_per_transaction.median()\n",
    "min_items = items_per_transaction.min()\n",
    "max_items = items_per_transaction.max()\n",
    "\n",
    "print(f\"Average Items per Transaction: {avg_items:.2f}\")\n",
    "print(f\"Median Items per Transaction: {median_items}\")\n",
    "print(f\"Min Items per Transaction: {min_items}\")\n",
    "print(f\"Max Items per Transaction: {max_items}\")\n",
    "\n",
    "# 3. Distribution of transaction sizes\n",
    "print(\"\\n3. Distribution of Transaction Sizes\")\n",
    "# Plot histogram of items per transaction\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(items_per_transaction, bins=30)\n",
    "plt.title('Distribution of Items per Transaction')\n",
    "plt.xlabel('Number of Items')\n",
    "plt.ylabel('Number of Transactions')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.savefig(os.path.join(plots_dir, 'transaction_size_histogram.png'))\n",
    "plt.close()\n",
    "\n",
    "# Calculate percentiles\n",
    "percentiles = np.percentile(items_per_transaction, [25, 50, 75, 90, 95, 99])\n",
    "print(\"\\nTransaction Size Percentiles:\")\n",
    "print(f\"25th percentile: {percentiles[0]:.1f} items\")\n",
    "print(f\"50th percentile (median): {percentiles[1]:.1f} items\")\n",
    "print(f\"75th percentile: {percentiles[2]:.1f} items\")\n",
    "print(f\"90th percentile: {percentiles[3]:.1f} items\")\n",
    "print(f\"95th percentile: {percentiles[4]:.1f} items\")\n",
    "print(f\"99th percentile: {percentiles[5]:.1f} items\")\n",
    "\n",
    "# Transaction size distribution (in bins)\n",
    "size_bins = [1, 5, 10, 15, 20, 30, 50, 100, np.inf]\n",
    "size_labels = ['1-4', '5-9', '10-14', '15-19', '20-29', '30-49', '50-99', '100+']\n",
    "transaction_size_binned = pd.cut(items_per_transaction, bins=size_bins, labels=size_labels)\n",
    "size_counts = transaction_size_binned.value_counts().sort_index()\n",
    "\n",
    "print(\"\\nTransaction Size Distribution:\")\n",
    "total_transactions = len(items_per_transaction)\n",
    "for size, count in size_counts.items():\n",
    "    percentage = (count / total_transactions) * 100\n",
    "    print(f\"{size} items: {count} transactions ({percentage:.2f}%)\")\n",
    "\n",
    "# Plot binned transaction sizes\n",
    "plt.figure(figsize=(10, 6))\n",
    "size_counts.plot(kind='bar')\n",
    "plt.title('Transaction Size Distribution')\n",
    "plt.xlabel('Number of Items')\n",
    "plt.ylabel('Number of Transactions')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, 'transaction_size_bins.png'))\n",
    "plt.close()\n",
    "\n",
    "# 4. Temporal patterns - heatmap showing day of week vs hour\n",
    "print(\"\\n4. Temporal Patterns - Day of Week vs Hour\")\n",
    "# Create hour-of-day vs day-of-week heatmap\n",
    "day_hour_counts = df.groupby(['Day', 'Hour'])['BillNo'].nunique().unstack()\n",
    "# Reorder days\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "day_hour_counts = day_hour_counts.reindex(day_order)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(day_hour_counts, cmap='YlGnBu', annot=False)\n",
    "plt.title('Number of Transactions by Day of Week and Hour')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Day of Week')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, 'day_hour_heatmap.png'))\n",
    "plt.close()\n",
    "\n",
    "# Most common hour for each day\n",
    "busiest_hours = day_hour_counts.idxmax(axis=1)\n",
    "print(\"\\nBusiest Hour for Each Day:\")\n",
    "for day, hour in busiest_hours.items():\n",
    "    print(f\"{day}: {hour}:00\")\n",
    "\n",
    "print(f\"\\nVisualizations saved to {plots_dir}\")\n",
    "print(\"\\nTransaction pattern analysis complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Analysis\n",
    "\n",
    "Examine the product-related characteristics:\n",
    "\n",
    "- **Top 10-20 most frequently purchased products**.\n",
    "- **Product category distribution**: Percentage of items in each category.\n",
    "- **Price distribution**: Across different product categories.\n",
    "- **Product popularity vs. price**: Correlation analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== PRODUCT ANALYSIS =====\n",
      "\n",
      "1. Top Most Frequently Purchased Products\n",
      "\n",
      "Top 20 Most Frequently Purchased Products:\n",
      "1. WHITE HANGING HEART T-LIGHT HOLDER: 2269 purchases (0.44%)\n",
      "2. JUMBO BAG RED RETROSPOT: 2087 purchases (0.40%)\n",
      "3. REGENCY CAKESTAND 3 TIER: 1930 purchases (0.37%)\n",
      "4. PARTY BUNTING: 1677 purchases (0.32%)\n",
      "5. LUNCH BAG RED RETROSPOT: 1570 purchases (0.30%)\n",
      "6. ASSORTED COLOUR BIRD ORNAMENT: 1465 purchases (0.28%)\n",
      "7. SET OF 3 CAKE TINS PANTRY DESIGN: 1360 purchases (0.26%)\n",
      "8. PACK OF 72 RETROSPOT CAKE CASES: 1328 purchases (0.26%)\n",
      "9. LUNCH BAG  BLACK SKULL.: 1315 purchases (0.25%)\n",
      "10. NATURAL SLATE HEART CHALKBOARD: 1246 purchases (0.24%)\n",
      "11. JUMBO BAG PINK POLKADOT: 1231 purchases (0.24%)\n",
      "12. HEART OF WICKER SMALL: 1206 purchases (0.23%)\n",
      "13. JUMBO STORAGE BAG SUKI: 1191 purchases (0.23%)\n",
      "14. PAPER CHAIN KIT 50'S CHRISTMAS: 1183 purchases (0.23%)\n",
      "15. JUMBO SHOPPER VINTAGE RED PAISLEY: 1181 purchases (0.23%)\n",
      "16. LUNCH BAG SPACEBOY DESIGN: 1169 purchases (0.22%)\n",
      "17. LUNCH BAG CARS BLUE: 1156 purchases (0.22%)\n",
      "18. SPOTTY BUNTING: 1133 purchases (0.22%)\n",
      "19. JAM MAKING SET PRINTED: 1123 purchases (0.22%)\n",
      "20. LUNCH BAG SUKI DESIGN: 1112 purchases (0.21%)\n",
      "\n",
      "2. Product Category Distribution\n",
      "\n",
      "Product Category Distribution:\n",
      "Kitchen & Dining: 105749 products (20.31%)\n",
      "Home Decor: 97277 products (18.69%)\n",
      "Stationery & Office: 47941 products (9.21%)\n",
      "Seasonal & Holidays: 40666 products (7.81%)\n",
      "Kids & Toys: 40642 products (7.81%)\n",
      "Textiles & Cozy Items: 25770 products (4.95%)\n",
      "Vintage & Collectibles: 24355 products (4.68%)\n",
      "Fashion & Accessories: 24224 products (4.65%)\n",
      "Party Supplies: 23609 products (4.53%)\n",
      "Storage & Organization: 22690 products (4.36%)\n",
      "Garden & Outdoor: 18558 products (3.56%)\n",
      "Crafts & DIY: 17090 products (3.28%)\n",
      "Lighting: 7022 products (1.35%)\n",
      "Games & Puzzles: 7013 products (1.35%)\n",
      "Electronics & Gadgets: 5269 products (1.01%)\n",
      "Bath & Body: 5024 products (0.97%)\n",
      "Gifts & Special Occasion: 3005 products (0.58%)\n",
      "Pets & Animals: 2012 products (0.39%)\n",
      "no_list: 963 products (0.18%)\n",
      "Books & Magazines: 851 products (0.16%)\n",
      "Miscellaneous: 754 products (0.14%)\n",
      "\n",
      "3. Price Distribution Across Categories\n",
      "\n",
      "Price Statistics by Category:\n",
      "Books & Magazines:\n",
      "  Min: £0.00\n",
      "  Max: £4287.63\n",
      "  Mean: £79.34\n",
      "  Median: £2.25\n",
      "  Std Dev: £399.07\n",
      "Miscellaneous:\n",
      "  Min: £0.00\n",
      "  Max: £13541.33\n",
      "  Mean: £20.74\n",
      "  Median: £1.25\n",
      "  Std Dev: £493.13\n",
      "Stationery & Office:\n",
      "  Min: £-11062.06\n",
      "  Max: £11062.06\n",
      "  Mean: £6.29\n",
      "  Median: £0.85\n",
      "  Std Dev: £110.27\n",
      "Storage & Organization:\n",
      "  Min: £0.00\n",
      "  Max: £125.00\n",
      "  Mean: £5.02\n",
      "  Median: £2.89\n",
      "  Std Dev: £6.35\n",
      "Garden & Outdoor:\n",
      "  Min: £0.00\n",
      "  Max: £649.50\n",
      "  Mean: £4.60\n",
      "  Median: £2.46\n",
      "  Std Dev: £8.20\n",
      "Electronics & Gadgets:\n",
      "  Min: £0.00\n",
      "  Max: £21.00\n",
      "  Mean: £4.35\n",
      "  Median: £3.75\n",
      "  Std Dev: £1.82\n",
      "Lighting:\n",
      "  Min: £0.00\n",
      "  Max: £99.96\n",
      "  Mean: £4.34\n",
      "  Median: £3.29\n",
      "  Std Dev: £4.39\n",
      "Vintage & Collectibles:\n",
      "  Min: £0.00\n",
      "  Max: £295.00\n",
      "  Mean: £4.10\n",
      "  Median: £2.46\n",
      "  Std Dev: £9.59\n",
      "Textiles & Cozy Items:\n",
      "  Min: £0.00\n",
      "  Max: £82.50\n",
      "  Mean: £3.74\n",
      "  Median: £3.75\n",
      "  Std Dev: £2.86\n",
      "Kitchen & Dining:\n",
      "  Min: £0.00\n",
      "  Max: £58.29\n",
      "  Mean: £3.69\n",
      "  Median: £2.55\n",
      "  Std Dev: £3.71\n",
      "Home Decor:\n",
      "  Min: £0.00\n",
      "  Max: £165.00\n",
      "  Mean: £3.67\n",
      "  Median: £2.46\n",
      "  Std Dev: £4.64\n",
      "Pets & Animals:\n",
      "  Min: £0.00\n",
      "  Max: £15.79\n",
      "  Mean: £3.32\n",
      "  Median: £2.95\n",
      "  Std Dev: £2.34\n",
      "Bath & Body:\n",
      "  Min: £0.00\n",
      "  Max: £12.46\n",
      "  Mean: £2.98\n",
      "  Median: £2.46\n",
      "  Std Dev: £2.01\n",
      "Kids & Toys:\n",
      "  Min: £0.00\n",
      "  Max: £65.00\n",
      "  Mean: £2.91\n",
      "  Median: £2.08\n",
      "  Std Dev: £2.79\n",
      "Gifts & Special Occasion:\n",
      "  Min: £0.00\n",
      "  Max: £83.33\n",
      "  Mean: £2.57\n",
      "  Median: £1.65\n",
      "  Std Dev: £3.93\n",
      "Crafts & DIY:\n",
      "  Min: £0.00\n",
      "  Max: £34.04\n",
      "  Mean: £2.55\n",
      "  Median: £1.95\n",
      "  Std Dev: £2.14\n",
      "Fashion & Accessories:\n",
      "  Min: £0.00\n",
      "  Max: £59.53\n",
      "  Mean: £2.48\n",
      "  Median: £1.63\n",
      "  Std Dev: £2.77\n",
      "Seasonal & Holidays:\n",
      "  Min: £0.00\n",
      "  Max: £34.00\n",
      "  Mean: £2.42\n",
      "  Median: £1.65\n",
      "  Std Dev: £2.59\n",
      "Games & Puzzles:\n",
      "  Min: £0.00\n",
      "  Max: £12.46\n",
      "  Mean: £2.14\n",
      "  Median: £1.25\n",
      "  Std Dev: £1.87\n",
      "Party Supplies:\n",
      "  Min: £0.00\n",
      "  Max: £15.79\n",
      "  Mean: £2.05\n",
      "  Median: £1.25\n",
      "  Std Dev: £1.98\n",
      "no_list:\n",
      "  Min: £0.00\n",
      "  Max: £7.46\n",
      "  Mean: £1.73\n",
      "  Median: £1.25\n",
      "  Std Dev: £0.85\n",
      "\n",
      "4. Product Popularity vs. Price Correlation\n",
      "\n",
      "Correlation between product popularity and price: -0.0050\n",
      "P-value: 0.7473\n",
      "The correlation is not statistically significant (p < 0.05).\n",
      "This represents a negligible correlation.\n",
      "\n",
      "Top 10 Most Popular Products with Average Prices:\n",
      "WHITE HANGING HEART T-LIGHT HOLDER: 2269.0 purchases, Average Price: £3.22\n",
      "JUMBO BAG RED RETROSPOT: 2087.0 purchases, Average Price: £2.49\n",
      "REGENCY CAKESTAND 3 TIER: 1930.0 purchases, Average Price: £14.04\n",
      "PARTY BUNTING: 1677.0 purchases, Average Price: £5.81\n",
      "LUNCH BAG RED RETROSPOT: 1570.0 purchases, Average Price: £2.14\n",
      "ASSORTED COLOUR BIRD ORNAMENT: 1465.0 purchases, Average Price: £1.72\n",
      "SET OF 3 CAKE TINS PANTRY DESIGN: 1360.0 purchases, Average Price: £5.86\n",
      "PACK OF 72 RETROSPOT CAKE CASES: 1328.0 purchases, Average Price: £0.77\n",
      "LUNCH BAG  BLACK SKULL.: 1315.0 purchases, Average Price: £2.10\n",
      "NATURAL SLATE HEART CHALKBOARD: 1246.0 purchases, Average Price: £3.59\n",
      "\n",
      "Top 10 Most Expensive Products with Popularity:\n",
      "AMAZON FEE: £6880.55, 2.0 purchases\n",
      "PICNIC BASKET WICKER 60 PIECES: £649.50, 2.0 purchases\n",
      "DOTCOM POSTAGE: £291.31, 708.0 purchases\n",
      "Manual: £206.78, 320.0 purchases\n",
      "RUSTIC  SEVENTEEN DRAWER SIDEBOARD: £158.91, 23.0 purchases\n",
      "REGENCY MIRROR WITH SHUTTERS: £156.43, 7.0 purchases\n",
      "VINTAGE BLUE KITCHEN CABINET: £149.17, 18.0 purchases\n",
      "VINTAGE RED KITCHEN CABINET: £144.44, 36.0 purchases\n",
      "CHEST NATURAL WOOD 20 DRAWERS: £118.08, 13.0 purchases\n",
      "LOVE SEAT ANTIQUE WHITE METAL: £114.75, 40.0 purchases\n",
      "\n",
      "Visualizations saved to C:\\Users\\moham\\Apriori_VS_Word2Vec\\analysis_plots\n",
      "\n",
      "Product analysis complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Path setup\n",
    "path = r'C:\\Users\\moham\\Apriori_VS_Word2Vec'\n",
    "excel_file = 'df_merged_items_category.xlsx'\n",
    "excel_file_path = os.path.join(path, excel_file)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel(excel_file_path)\n",
    "\n",
    "# Create plot directory if it doesn't exist\n",
    "plots_dir = os.path.join(path, 'analysis_plots')\n",
    "if not os.path.exists(plots_dir):\n",
    "    os.makedirs(plots_dir)\n",
    "\n",
    "# ===== PRODUCT ANALYSIS =====\n",
    "print(\"\\n===== PRODUCT ANALYSIS =====\")\n",
    "\n",
    "# 1. Top products by frequency\n",
    "print(\"\\n1. Top Most Frequently Purchased Products\")\n",
    "product_counts = df['Itemname'].value_counts()\n",
    "top_20_products = product_counts.head(20)\n",
    "\n",
    "print(\"\\nTop 20 Most Frequently Purchased Products:\")\n",
    "for i, (product, count) in enumerate(top_20_products.items(), 1):\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"{i}. {product}: {count} purchases ({percentage:.2f}%)\")\n",
    "\n",
    "# Plot top 20 products\n",
    "plt.figure(figsize=(14, 10))\n",
    "top_20_products.plot(kind='barh')\n",
    "plt.title('Top 20 Most Frequently Purchased Products')\n",
    "plt.xlabel('Number of Purchases')\n",
    "plt.ylabel('Product Name')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, 'top_20_products.png'))\n",
    "plt.close()\n",
    "\n",
    "# 2. Product category distribution\n",
    "if 'category' in df.columns:\n",
    "    print(\"\\n2. Product Category Distribution\")\n",
    "    category_counts = df['category'].value_counts()\n",
    "    \n",
    "    print(\"\\nProduct Category Distribution:\")\n",
    "    for category, count in category_counts.items():\n",
    "        percentage = (count / len(df)) * 100\n",
    "        print(f\"{category}: {count} products ({percentage:.2f}%)\")\n",
    "    \n",
    "    # Plot category distribution\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    category_counts.plot(kind='bar')\n",
    "    plt.title('Product Category Distribution')\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Number of Products')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, 'category_distribution_bar.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Pie chart for categories\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.pie(category_counts, labels=category_counts.index, autopct='%1.1f%%')\n",
    "    plt.title('Product Category Distribution')\n",
    "    plt.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, 'category_distribution_pie.png'))\n",
    "    plt.close()\n",
    "\n",
    "# 3. Price distribution across categories\n",
    "if 'Price' in df.columns and 'category' in df.columns:\n",
    "    print(\"\\n3. Price Distribution Across Categories\")\n",
    "    \n",
    "    # Basic price statistics by category\n",
    "    price_stats = df.groupby('category')['Price'].agg(['min', 'max', 'mean', 'median', 'std'])\n",
    "    price_stats = price_stats.sort_values('mean', ascending=False)\n",
    "    \n",
    "    print(\"\\nPrice Statistics by Category:\")\n",
    "    for category, stats in price_stats.iterrows():\n",
    "        print(f\"{category}:\")\n",
    "        print(f\"  Min: £{stats['min']:.2f}\")\n",
    "        print(f\"  Max: £{stats['max']:.2f}\")\n",
    "        print(f\"  Mean: £{stats['mean']:.2f}\")\n",
    "        print(f\"  Median: £{stats['median']:.2f}\")\n",
    "        print(f\"  Std Dev: £{stats['std']:.2f}\")\n",
    "    \n",
    "    # Box plot of price by category\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.boxplot(x='category', y='Price', data=df)\n",
    "    plt.title('Price Distribution by Category')\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Price (£)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, 'price_distribution_boxplot.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Violin plot for more detailed distribution\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.violinplot(x='category', y='Price', data=df, cut=0)\n",
    "    plt.title('Price Distribution by Category (Violin Plot)')\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Price (£)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, 'price_distribution_violin.png'))\n",
    "    plt.close()\n",
    "\n",
    "# 4. Product popularity vs. price correlation\n",
    "if 'Price' in df.columns and 'Itemname' in df.columns:\n",
    "    print(\"\\n4. Product Popularity vs. Price Correlation\")\n",
    "    \n",
    "    # Get product popularity and average price\n",
    "    product_data = df.groupby('Itemname').agg({\n",
    "        'Itemname': 'count',\n",
    "        'Price': 'mean'\n",
    "    }).rename(columns={'Itemname': 'Frequency'})\n",
    "    \n",
    "    # Calculate correlation\n",
    "    correlation, p_value = pearsonr(product_data['Frequency'], product_data['Price'])\n",
    "    print(f\"\\nCorrelation between product popularity and price: {correlation:.4f}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        significance = \"statistically significant\"\n",
    "    else:\n",
    "        significance = \"not statistically significant\"\n",
    "    \n",
    "    print(f\"The correlation is {significance} (p < 0.05).\")\n",
    "    \n",
    "    if correlation < -0.5:\n",
    "        interpretation = \"strong negative\"\n",
    "    elif correlation < -0.3:\n",
    "        interpretation = \"moderate negative\"\n",
    "    elif correlation < -0.1:\n",
    "        interpretation = \"weak negative\"\n",
    "    elif correlation < 0.1:\n",
    "        interpretation = \"negligible\"\n",
    "    elif correlation < 0.3:\n",
    "        interpretation = \"weak positive\"\n",
    "    elif correlation < 0.5:\n",
    "        interpretation = \"moderate positive\"\n",
    "    else:\n",
    "        interpretation = \"strong positive\"\n",
    "    \n",
    "    print(f\"This represents a {interpretation} correlation.\")\n",
    "    \n",
    "    # Scatter plot of price vs. popularity\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(product_data['Price'], product_data['Frequency'], alpha=0.5)\n",
    "    plt.title('Product Popularity vs. Price')\n",
    "    plt.xlabel('Average Price (£)')\n",
    "    plt.ylabel('Number of Purchases')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(product_data['Price'], product_data['Frequency'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(product_data['Price'], p(product_data['Price']), \"r--\", \n",
    "             label=f\"Trend line (y={z[0]:.2f}x+{z[1]:.2f})\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, 'popularity_vs_price.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Log-scale scatter plot (often better for this type of data)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(product_data['Price'], product_data['Frequency'], alpha=0.5)\n",
    "    plt.title('Product Popularity vs. Price (Log Scale)')\n",
    "    plt.xlabel('Average Price (£)')\n",
    "    plt.ylabel('Number of Purchases (Log Scale)')\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, 'popularity_vs_price_log.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Top 10 most popular products with their prices\n",
    "    top_10_with_price = product_data.sort_values('Frequency', ascending=False).head(10)\n",
    "    print(\"\\nTop 10 Most Popular Products with Average Prices:\")\n",
    "    for product, data in top_10_with_price.iterrows():\n",
    "        print(f\"{product}: {data['Frequency']} purchases, Average Price: £{data['Price']:.2f}\")\n",
    "    \n",
    "    # Top 10 most expensive products with their popularity\n",
    "    top_10_expensive = product_data.sort_values('Price', ascending=False).head(10)\n",
    "    print(\"\\nTop 10 Most Expensive Products with Popularity:\")\n",
    "    for product, data in top_10_expensive.iterrows():\n",
    "        print(f\"{product}: £{data['Price']:.2f}, {data['Frequency']} purchases\")\n",
    "\n",
    "print(f\"\\nVisualizations saved to {plots_dir}\")\n",
    "print(\"\\nProduct analysis complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
