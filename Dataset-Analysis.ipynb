{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis\n",
    "\n",
    "- **How many rows**: Number of roows in the dataset.\n",
    "- **How many columns**: Number of columns in the dataset.\n",
    "- **List of the columns**: List of columns in the dataset.\n",
    "- **Total Products**: Number of products in the dataset.\n",
    "- **Distinct Products**: Number of unique products.\n",
    "- **Total Transactions**: Number of transactions recorded.\n",
    "- **Total Customers**: Number of customers in the dataset.\n",
    "- **Distinct Categories**: Number of unique product categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ===== DATA ANALYSIS ===== \n",
      "\n",
      "Dataset Overview (Whole Dataset):\n",
      "==================================================\n",
      "  Rows: 520,609\n",
      "  Columns: 8\n",
      "  Column Names: BillNo, Itemname, Quantity, Date, Price, CustomerID, Country, category\n",
      "==================================================\n",
      "  Total Products: 520,609\n",
      "  Distinct Products: 4,185\n",
      "  Total Transactions: 20,208\n",
      "  Total Customers: 4,297\n",
      "  Distinct Categories: 21\n",
      "==================================================\n",
      "\n",
      "Comparison Table:\n",
      "                     Full Dataset  First Third  Last Two Thirds\n",
      "Metric                                                         \n",
      "Rows                       520609       173536           347073\n",
      "Columns                         8            8                8\n",
      "Total Products             520609       173536           347073\n",
      "Distinct Products            4185         3326             3738\n",
      "Total Transactions          20208         6847            13362\n",
      "Total Customers              4297         2489             3632\n",
      "Distinct Categories            21           21               21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ===== CONFIGURATION =====\n",
    "BACKGROUND_COLOR = \"#f5f5f5\"  # Light gray background\n",
    "TEXT_COLOR = \"#333333\"        # Dark gray for text\n",
    "\n",
    "# Set path and file name\n",
    "path = r'C:\\Users\\moham\\Apriori_VS_Word2Vec\\Dataset'\n",
    "excel_file = 'df_merged_items_category.xlsx'\n",
    "excel_file_path = os.path.join(path, excel_file)\n",
    "\n",
    "# ===== DATA LOADING =====\n",
    "# Load the dataset\n",
    "df = pd.read_excel(excel_file_path)\n",
    "print(\"\\n ===== DATA ANALYSIS ===== \\n\")\n",
    "\n",
    "# Create output directory for plots if it doesn't exist\n",
    "plots_dir = os.path.join(path, 'Analysis_plots')\n",
    "if not os.path.exists(plots_dir):\n",
    "    os.makedirs(plots_dir)\n",
    "\n",
    "# ===== FUNCTION DEFINITION =====\n",
    "def compute_stats(dataframe):\n",
    "    \"\"\"\n",
    "    Compute key statistics for the given DataFrame.\n",
    "    Returns a dictionary with analysis results.\n",
    "    \"\"\"\n",
    "    stats = {}\n",
    "    stats['Rows'] = len(dataframe)\n",
    "    stats['Columns'] = len(dataframe.columns)\n",
    "    stats['Total Products'] = len(dataframe)  # Each row represents a product purchase\n",
    "    stats['Distinct Products'] = dataframe['Itemname'].nunique()\n",
    "    stats['Total Transactions'] = dataframe['BillNo'].nunique()\n",
    "    stats['Total Customers'] = int(dataframe['CustomerID'].dropna().nunique())\n",
    "    stats['Distinct Categories'] = dataframe['category'].nunique()\n",
    "    return stats\n",
    "\n",
    "# ===== ANALYSIS FOR DIFFERENT PARTITIONS =====\n",
    "# Whole dataset statistics\n",
    "stats_whole = compute_stats(df)\n",
    "\n",
    "# Compute the index to split the first third from the remaining two thirds\n",
    "one_third_index = len(df) // 3\n",
    "\n",
    "# Split into first third and last two thirds\n",
    "df_first_third = df.iloc[:one_third_index]\n",
    "df_last_two_thirds = df.iloc[one_third_index:]\n",
    "\n",
    "stats_first_third = compute_stats(df_first_third)\n",
    "stats_last_two_thirds = compute_stats(df_last_two_thirds)\n",
    "\n",
    "# ===== PRINT OVERVIEW FOR WHOLE DATASET =====\n",
    "print(\"Dataset Overview (Whole Dataset):\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Rows: {stats_whole['Rows']:,}\")\n",
    "print(f\"  Columns: {stats_whole['Columns']}\")\n",
    "print(f\"  Column Names: {', '.join(df.columns.tolist())}\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Total Products: {stats_whole['Total Products']:,}\")\n",
    "print(f\"  Distinct Products: {stats_whole['Distinct Products']:,}\")\n",
    "print(f\"  Total Transactions: {stats_whole['Total Transactions']:,}\")\n",
    "print(f\"  Total Customers: {stats_whole['Total Customers']:,}\")\n",
    "print(f\"  Distinct Categories: {stats_whole['Distinct Categories']}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ===== COMPARISON TABLE =====\n",
    "# Create a DataFrame that compares statistics of the whole dataset,\n",
    "# the first third, and the last two thirds.\n",
    "comparison_data = {\n",
    "    \"Full Dataset\": stats_whole,\n",
    "    \"First Third\": stats_first_third,\n",
    "    \"Last Two Thirds\": stats_last_two_thirds\n",
    "}\n",
    "comparison_table = pd.DataFrame(comparison_data)\n",
    "comparison_table.index.name = \"Metric\"\n",
    "\n",
    "print(\"\\nComparison Table:\")\n",
    "print(comparison_table)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file saved to: C:\\Users\\moham\\Apriori_VS_Word2Vec\\Dataset\\distinct_products_with_categories.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path = r'C:\\Users\\moham\\Apriori_VS_Word2Vec\\Dataset'\n",
    "excel_file = 'df_merged_items_category.xlsx'\n",
    "excel_file_path = os.path.join(path, excel_file)\n",
    "\n",
    "def load_dataset(file_path):\n",
    "    return pd.read_excel(file_path)\n",
    "\n",
    "data_excel = load_dataset(excel_file_path)\n",
    "data_excel.dropna(subset=['Itemname'], inplace=True)   \n",
    "output_file = os.path.join(path, 'unique_items.xlsx')\n",
    "\n",
    "unique_items_df = pd.DataFrame({'unique_items': data_excel['Itemname'].unique()})\n",
    "unique_items_df.to_excel(output_file, index=False)\n",
    "\n",
    "# DataFrame with distinct products and their categories\n",
    "distinct_products_df = df[['Itemname', 'category']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Sort by category and then by product name for better organization\n",
    "distinct_products_df = distinct_products_df.sort_values(['category', 'Itemname'])\n",
    "\n",
    "# Save to Excel file\n",
    "output_file = os.path.join(path, 'distinct_products_with_categories.xlsx')\n",
    "distinct_products_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Excel file saved to: {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transaction Patterns\n",
    "\n",
    "Analyze the purchasing patterns visible in the data:\n",
    "\n",
    "- **Average items per transaction**.\n",
    "- **Distribution of transaction sizes**: Histogram showing the number of items per invoice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ===== TRANSACTION PATTERNS ANALYSIS ===== \n",
      "\n",
      "Average Items per Transaction (Whole Dataset):\n",
      "==================================================\n",
      " Average Items: 25.76\n",
      " Median Items: 15.0\n",
      " Min Items: 1\n",
      " Max Items: 1114\n",
      "==================================================\n",
      "\n",
      "Transaction Size Percentiles (Whole Dataset):\n",
      " 25th percentile: 5.0 items\n",
      " 50th percentile (median): 15.0 items\n",
      " 75th percentile: 28.0 items\n",
      " 90th percentile: 53.0 items\n",
      " 95th percentile: 77.0 items\n",
      " 99th percentile: 218.0 items\n",
      "==================================================\n",
      "\n",
      "Comparison Table (Transaction Metrics):\n",
      "                   Whole  First Third  Last Two Thirds\n",
      "Metric                                                \n",
      "Avg Items       25.76252    25.344823         25.97463\n",
      "Median Items    15.00000    14.000000         15.00000\n",
      "Min Items        1.00000     1.000000          1.00000\n",
      "Max Items     1114.00000   675.000000       1114.00000\n",
      "P25              5.00000     6.000000          5.00000\n",
      "P50             15.00000    14.000000         15.00000\n",
      "P75             28.00000    28.000000         29.00000\n",
      "P90             53.00000    52.000000         53.00000\n",
      "P95             77.00000    73.000000         79.95000\n",
      "P99            218.00000   216.540000        218.39000\n",
      "\n",
      "Comparison table saved to: C:\\Users\\moham\\Apriori_VS_Word2Vec\\Dataset\\Analysis_plots\\transaction_comparison_table.xlsx\n",
      "Plot saved for Whole Dataset at: C:\\Users\\moham\\Apriori_VS_Word2Vec\\Dataset\\Analysis_plots\\transaction_size_distribution_Whole_Dataset.png\n",
      "Plot saved for First Third at: C:\\Users\\moham\\Apriori_VS_Word2Vec\\Dataset\\Analysis_plots\\transaction_size_distribution_First_Third.png\n",
      "Plot saved for Last Two Thirds at: C:\\Users\\moham\\Apriori_VS_Word2Vec\\Dataset\\Analysis_plots\\transaction_size_distribution_Last_Two_Thirds.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "# ===== VISUALIZATION SETTINGS =====\n",
    "MAIN_COLOR = \"#1f77b4\"       # Primary blue\n",
    "TERTIARY_COLOR = \"#2ca02c\"   # Green for additional elements\n",
    "BACKGROUND_COLOR = \"#f5f5f5\" # Light gray background\n",
    "TEXT_COLOR = \"#333333\"       # Dark gray for text\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette([MAIN_COLOR, TERTIARY_COLOR])\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Arial', 'Helvetica', 'DejaVu Sans']\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['axes.facecolor'] = BACKGROUND_COLOR\n",
    "plt.rcParams['axes.edgecolor'] = TEXT_COLOR\n",
    "plt.rcParams['axes.labelcolor'] = TEXT_COLOR\n",
    "plt.rcParams['text.color'] = TEXT_COLOR\n",
    "plt.rcParams['xtick.color'] = TEXT_COLOR\n",
    "plt.rcParams['ytick.color'] = TEXT_COLOR\n",
    "\n",
    "# ===== DATA LOADING =====\n",
    "path = r'C:\\Users\\moham\\Apriori_VS_Word2Vec\\Dataset'\n",
    "excel_file = 'df_merged_items_category.xlsx'\n",
    "excel_file_path = os.path.join(path, excel_file)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel(excel_file_path)\n",
    "\n",
    "# Ensure 'Date' is in datetime format if the column exists\n",
    "if 'Date' in df.columns:\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['Date']):\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Create output directory for plots if it doesn't exist\n",
    "plots_dir = os.path.join(path, 'Analysis_plots')\n",
    "if not os.path.exists(plots_dir):\n",
    "    os.makedirs(plots_dir)\n",
    "\n",
    "# ===== HELPER FUNCTION FOR TRANSACTION ANALYSIS =====\n",
    "def compute_transaction_metrics(dataframe):\n",
    "    \"\"\"\n",
    "    Compute transaction metrics:\n",
    "      - items per transaction: average, median, min, max\n",
    "      - transaction size percentiles (25th, 50th, 75th, 90th, 95th, 99th)\n",
    "    Returns a tuple with (metrics dictionary, items_per_transaction series)\n",
    "    \"\"\"\n",
    "    # Group by 'BillNo' to compute items per transaction\n",
    "    items_per_transaction = dataframe.groupby('BillNo').size()\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['Avg Items'] = items_per_transaction.mean()\n",
    "    metrics['Median Items'] = items_per_transaction.median()\n",
    "    metrics['Min Items'] = items_per_transaction.min()\n",
    "    metrics['Max Items'] = items_per_transaction.max()\n",
    "    \n",
    "    # Compute percentiles\n",
    "    percentiles = np.percentile(items_per_transaction, [25, 50, 75, 90, 95, 99])\n",
    "    metrics['P25'] = percentiles[0]\n",
    "    metrics['P50'] = percentiles[1]  # same as median\n",
    "    metrics['P75'] = percentiles[2]\n",
    "    metrics['P90'] = percentiles[3]\n",
    "    metrics['P95'] = percentiles[4]\n",
    "    metrics['P99'] = percentiles[5]\n",
    "    \n",
    "    return metrics, items_per_transaction\n",
    "\n",
    "# ===== DATA PARTITIONING =====\n",
    "# Split dataset into whole, first third, and last two thirds.\n",
    "n = len(df)\n",
    "one_third_index = n // 3\n",
    "\n",
    "df_whole = df.copy()\n",
    "df_first_third = df.iloc[:one_third_index]\n",
    "df_last_two_thirds = df.iloc[one_third_index:]\n",
    "\n",
    "# ===== ANALYZE TRANSACTION PATTERNS =====\n",
    "print(\"\\n ===== TRANSACTION PATTERNS ANALYSIS ===== \\n\")\n",
    "\n",
    "# Compute metrics and items-per-transaction series for each partition.\n",
    "metrics_whole, items_whole = compute_transaction_metrics(df_whole)\n",
    "metrics_first_third, items_first_third = compute_transaction_metrics(df_first_third)\n",
    "metrics_last_two_thirds, items_last_two_thirds = compute_transaction_metrics(df_last_two_thirds)\n",
    "\n",
    "# Display overall transaction metrics (from the whole dataset) as an example.\n",
    "print(\"Average Items per Transaction (Whole Dataset):\")\n",
    "print(\"=\" * 50)\n",
    "print(f\" Average Items: {metrics_whole['Avg Items']:.2f}\")\n",
    "print(f\" Median Items: {metrics_whole['Median Items']}\")\n",
    "print(f\" Min Items: {metrics_whole['Min Items']}\")\n",
    "print(f\" Max Items: {metrics_whole['Max Items']}\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nTransaction Size Percentiles (Whole Dataset):\")\n",
    "print(f\" 25th percentile: {metrics_whole['P25']:.1f} items\")\n",
    "print(f\" 50th percentile (median): {metrics_whole['P50']:.1f} items\")\n",
    "print(f\" 75th percentile: {metrics_whole['P75']:.1f} items\")\n",
    "print(f\" 90th percentile: {metrics_whole['P90']:.1f} items\")\n",
    "print(f\" 95th percentile: {metrics_whole['P95']:.1f} items\")\n",
    "print(f\" 99th percentile: {metrics_whole['P99']:.1f} items\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ===== COMPARISON TABLE =====\n",
    "comparison_data = {\n",
    "    \"Whole\": metrics_whole,\n",
    "    \"First Third\": metrics_first_third,\n",
    "    \"Last Two Thirds\": metrics_last_two_thirds\n",
    "}\n",
    "comparison_table = pd.DataFrame(comparison_data)\n",
    "comparison_table.index.name = \"Metric\"\n",
    "print(\"\\nComparison Table (Transaction Metrics):\")\n",
    "print(comparison_table)\n",
    "\n",
    "# Save the comparison table to an Excel file.\n",
    "comparison_table_file = os.path.join(plots_dir, \"transaction_comparison_table.xlsx\")\n",
    "comparison_table.to_excel(comparison_table_file)\n",
    "print(f\"\\nComparison table saved to: {comparison_table_file}\")\n",
    "\n",
    "# ===== PLOTTING FUNCTION =====\n",
    "def plot_transaction_distribution(items_series, title, save_path):\n",
    "    \"\"\"\n",
    "    Plot the transaction size distribution given a series of items per transaction.\n",
    "    Saves the plot to the provided save_path.\n",
    "    \"\"\"\n",
    "    # Define bins and labels\n",
    "    size_bins = [1, 5, 10, 15, 20, 30, 50, 100, np.inf]\n",
    "    size_labels = ['1-4', '5-9', '10-14', '15-19', '20-29', '30-49', '50-99', '100+']\n",
    "    \n",
    "    # Bin the transaction sizes\n",
    "    transaction_binned = pd.cut(items_series, bins=size_bins, labels=size_labels)\n",
    "    size_counts = transaction_binned.value_counts().sort_index()\n",
    "    total_transactions = len(items_series)\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(12, 7), facecolor=BACKGROUND_COLOR)\n",
    "    bars = plt.bar(size_counts.index.astype(str), size_counts.values, color=MAIN_COLOR, edgecolor='white')\n",
    "    plt.title(f'Transaction Size Distribution - {title}', fontweight='bold', fontsize=16, color=TEXT_COLOR)\n",
    "    plt.xlabel('Number of Items', fontsize=14, color=TEXT_COLOR)\n",
    "    plt.ylabel('Transactions', fontsize=14, color=TEXT_COLOR)\n",
    "    \n",
    "    # Annotate bars with percentage values\n",
    "    for i, v in enumerate(size_counts.values):\n",
    "        percentage = (v / total_transactions) * 100\n",
    "        plt.text(i, v + 0.05 * total_transactions, f\"{percentage:.1f}%\", ha='center', fontsize=10, \n",
    "                 fontweight='bold', color=TEXT_COLOR)\n",
    "    \n",
    "    # Highlight the bin with the maximum count\n",
    "    max_bin = size_counts.idxmax()\n",
    "    max_idx = list(size_counts.index).index(max_bin)\n",
    "    bars[max_idx].set_edgecolor('black')\n",
    "    bars[max_idx].set_linewidth(2)\n",
    "    \n",
    "    plt.grid(axis='y', alpha=0.3, color=\"#cccccc\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close()  # Close the figure to free memory\n",
    "\n",
    "# ===== GENERATE AND SAVE SEPARATE PLOTS =====\n",
    "# Dictionary of partitions with names and items_per_transaction series.\n",
    "partitions = {\n",
    "    \"Whole_Dataset\": items_whole,\n",
    "    \"First_Third\": items_first_third,\n",
    "    \"Last_Two_Thirds\": items_last_two_thirds\n",
    "}\n",
    "\n",
    "for partition_name, items_series in partitions.items():\n",
    "    plot_title = partition_name.replace(\"_\", \" \")\n",
    "    save_file = os.path.join(plots_dir, f\"transaction_size_distribution_{partition_name}.png\")\n",
    "    plot_transaction_distribution(items_series, plot_title, save_file)\n",
    "    print(f\"Plot saved for {plot_title} at: {save_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Products Analysis\n",
    "\n",
    "Examine the product-related characteristics:\n",
    "\n",
    "- **Top 10 most frequently purchased products**.\n",
    "- **Product category distribution**: Percentage of items in each category.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Top Products for: Whole_Dataset\n",
      "Top products plot saved to: C:\\Users\\moham\\Apriori_VS_Word2Vec\\Dataset\\Analysis_plots\\top_products_Whole_Dataset.png\n",
      "\n",
      "Processing Category Distribution for: Whole_Dataset\n",
      "Category distribution plot saved to: C:\\Users\\moham\\Apriori_VS_Word2Vec\\Dataset\\Analysis_plots\\category_distribution_Whole_Dataset.png\n",
      "\n",
      "Processing Top Products for: First_Third\n",
      "Top products plot saved to: C:\\Users\\moham\\Apriori_VS_Word2Vec\\Dataset\\Analysis_plots\\top_products_First_Third.png\n",
      "\n",
      "Processing Category Distribution for: First_Third\n",
      "Category distribution plot saved to: C:\\Users\\moham\\Apriori_VS_Word2Vec\\Dataset\\Analysis_plots\\category_distribution_First_Third.png\n",
      "\n",
      "Processing Top Products for: Last_Two_Thirds\n",
      "Top products plot saved to: C:\\Users\\moham\\Apriori_VS_Word2Vec\\Dataset\\Analysis_plots\\top_products_Last_Two_Thirds.png\n",
      "\n",
      "Processing Category Distribution for: Last_Two_Thirds\n",
      "Category distribution plot saved to: C:\\Users\\moham\\Apriori_VS_Word2Vec\\Dataset\\Analysis_plots\\category_distribution_Last_Two_Thirds.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "# ===== VISUALIZATION SETTINGS =====\n",
    "MAIN_COLOR = \"#1f77b4\"       # Primary blue\n",
    "TERTIARY_COLOR = \"#2ca02c\"   # Green for additional elements\n",
    "BACKGROUND_COLOR = \"#f5f5f5\" # Light gray background\n",
    "TEXT_COLOR = \"#333333\"       # Dark gray for text\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette([MAIN_COLOR, TERTIARY_COLOR])\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Arial', 'Helvetica', 'DejaVu Sans']\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['axes.facecolor'] = BACKGROUND_COLOR\n",
    "plt.rcParams['axes.edgecolor'] = TEXT_COLOR\n",
    "plt.rcParams['axes.labelcolor'] = TEXT_COLOR\n",
    "plt.rcParams['text.color'] = TEXT_COLOR\n",
    "plt.rcParams['xtick.color'] = TEXT_COLOR\n",
    "plt.rcParams['ytick.color'] = TEXT_COLOR\n",
    "\n",
    "# ===== DATA LOADING =====\n",
    "path = r'C:\\Users\\moham\\Apriori_VS_Word2Vec\\Dataset'\n",
    "excel_file = 'df_merged_items_category.xlsx'\n",
    "excel_file_path = os.path.join(path, excel_file)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel(excel_file_path)\n",
    "\n",
    "# Ensure 'Date' is in datetime format if the column exists\n",
    "if 'Date' in df.columns:\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['Date']):\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Create output directory for plots if it doesn't exist\n",
    "plots_dir = os.path.join(path, 'Analysis_plots')\n",
    "if not os.path.exists(plots_dir):\n",
    "    os.makedirs(plots_dir)\n",
    "\n",
    "# ===== DATA PARTITIONING =====\n",
    "# Split dataset into Whole, First Third, and Last Two Thirds.\n",
    "n = len(df)\n",
    "one_third_index = n // 3\n",
    "\n",
    "df_whole = df.copy()\n",
    "df_first_third = df.iloc[:one_third_index]\n",
    "df_last_two_thirds = df.iloc[one_third_index:]\n",
    "\n",
    "partitions = {\n",
    "    \"Whole_Dataset\": df_whole,\n",
    "    \"First_Third\": df_first_third,\n",
    "    \"Last_Two_Thirds\": df_last_two_thirds\n",
    "}\n",
    "\n",
    "# ===== PRODUCT ANALYSIS FUNCTIONS =====\n",
    "def plot_top_products(dataframe, partition_name, save_dir):\n",
    "    \"\"\"\n",
    "    Plot the top 10 products by frequency for the given partition.\n",
    "    The plot is saved as 'top_products_{partition_name}.png'.\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing Top Products for: {partition_name}\")\n",
    "    top_products = dataframe['Itemname'].value_counts().head(10)\n",
    "    total_items = len(dataframe)\n",
    "    \n",
    "    plt.figure(figsize=(14, 10), facecolor=BACKGROUND_COLOR)\n",
    "    # Reverse the order for a horizontal bar plot (largest at the top)\n",
    "    bars = plt.barh(top_products.index[::-1], top_products.values[::-1], color=MAIN_COLOR, edgecolor='white')\n",
    "    plt.title(f\"Top 10 Products by Frequency - {partition_name.replace('_', ' ')}\", \n",
    "              fontweight='bold', fontsize=16, color=TEXT_COLOR)\n",
    "    plt.xlabel(\"Number of Occurrences\", fontsize=14, color=TEXT_COLOR)\n",
    "    plt.ylabel(\"Product Name\", fontsize=14, color=TEXT_COLOR)\n",
    "    \n",
    "    # Add count annotations\n",
    "    for i, bar in enumerate(bars):\n",
    "        value = top_products.values[::-1][i]\n",
    "        plt.text(value + 10, bar.get_y() + bar.get_height()/2, \n",
    "                 f\"{value}\", va='center', fontsize=10, color=TEXT_COLOR)\n",
    "    \n",
    "    plt.grid(axis='x', alpha=0.3, color=\"#cccccc\")\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(save_dir, f\"top_products_{partition_name}.png\")\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Top products plot saved to: {save_path}\")\n",
    "\n",
    "def plot_category_distribution(dataframe, partition_name, save_dir):\n",
    "    \"\"\"\n",
    "    Plot the product category distribution for the given partition if 'category' column exists.\n",
    "    The plot is saved as 'category_distribution_{partition_name}.png'.\n",
    "    \"\"\"\n",
    "    if 'category' not in dataframe.columns:\n",
    "        print(f\"No 'category' column found for {partition_name}. Skipping category distribution plot.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nProcessing Category Distribution for: {partition_name}\")\n",
    "    category_counts = dataframe['category'].value_counts().head(10)\n",
    "    total_items = len(dataframe)\n",
    "    \n",
    "    plt.figure(figsize=(14, 8), facecolor=BACKGROUND_COLOR)\n",
    "    bars = plt.bar(category_counts.index, category_counts.values, color=MAIN_COLOR, edgecolor='white')\n",
    "    plt.title(f\"Product Categories Distribution - {partition_name.replace('_', ' ')}\", \n",
    "              fontweight='bold', fontsize=16, color=TEXT_COLOR)\n",
    "    plt.xlabel(\"Category\", fontsize=14, color=TEXT_COLOR)\n",
    "    plt.ylabel(\"Number of Items\", fontsize=14, color=TEXT_COLOR)\n",
    "    plt.xticks(rotation=45, ha='right', color=TEXT_COLOR)\n",
    "    \n",
    "    # Add value annotations on top of each bar\n",
    "    for i, bar in enumerate(bars):\n",
    "        value = category_counts.values[i]\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, value + 5, \n",
    "                 f\"{value}\", ha='center', va='bottom', \n",
    "                 fontsize=10, color=TEXT_COLOR, fontweight='bold')\n",
    "    \n",
    "    plt.grid(axis='y', alpha=0.3, color=\"#cccccc\")\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(save_dir, f\"category_distribution_{partition_name}.png\")\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Category distribution plot saved to: {save_path}\")\n",
    "\n",
    "# ===== GENERATE PLOTS FOR EACH PARTITION =====\n",
    "for partition_name, partition_df in partitions.items():\n",
    "    # Top Products Plot\n",
    "    plot_top_products(partition_df, partition_name, plots_dir)\n",
    "    \n",
    "    # Product Category Distribution Plot\n",
    "    plot_category_distribution(partition_df, partition_name, plots_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
